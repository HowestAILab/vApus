<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Confluent.Kafka</name>
    </assembly>
    <members>
        <member name="T:Confluent.Kafka.BrokerMetadata">
            <summary>
                Metadata pertaining to a single Kafka broker.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.BrokerMetadata.#ctor(System.Int32,System.String,System.Int32)">
            <summary>
                Initializes a new BrokerMetadata class instance.
            </summary>
            <param name="brokerId">
                The Kafka broker id.
            </param>
            <param name="host">
                The Kafka broker hostname.
            </param>
            <param name="port">
                The Kafka broker port.
            </param>
        </member>
        <member name="P:Confluent.Kafka.BrokerMetadata.BrokerId">
            <summary>
                Gets the Kafka broker id.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.BrokerMetadata.Host">
            <summary>
                Gets the Kafka broker hostname.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.BrokerMetadata.Port">
            <summary>
                Gets the Kafka broker port.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.BrokerMetadata.ToString">
            <summary>
                Returns a JSON representation of the BrokerMetadata object.
            </summary>
            <returns>
                A JSON representation of the BrokerMetadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.CommittedOffsets">
            <summary>
                Encapsulates information provided to a Consumer's OnOffsetsCommitted
                event - per-partition offsets and success/error together with overall 
                success/error of the commit operation.
            </summary> 
            <remarks>
                Possible error conditions:
                - Entire request failed: Error is set, but not per-partition errors.
                - All partitions failed: Error is set to the value of the last failed partition, but each partition may have different errors.
                - Some partitions failed: global error is success.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.CommittedOffsets.#ctor(System.Collections.Generic.IList{Confluent.Kafka.TopicPartitionOffsetError},Confluent.Kafka.Error)">
            <summary>
                Initializes a new instance of CommittedOffsets.
            </summary>
            <param name="offsets">
                per-partition offsets and success/error.
            </param>
            <param name="error">
                overall operation success/error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.CommittedOffsets.#ctor(System.Collections.Generic.IList{Confluent.Kafka.TopicPartitionOffsetError})">
            <summary>
                Initializes a new instance of CommittedOffsets with
                overall operation success.
            </summary>
            <param name="offsets">
                per-partition offsets and success/error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.CommittedOffsets.#ctor(Confluent.Kafka.Error)">
            <summary>
                Initializes a new instance of CommittedOffsets with
                an empty per-partition list and the overall 
                success/error <paramref name="error" />.
            </summary>
            <param name="error"></param>
        </member>
        <member name="P:Confluent.Kafka.CommittedOffsets.Error">
            <summary>
                Gets the overall operation success/error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.CommittedOffsets.Offsets">
            <summary>
                Gets the per-partition offsets and success/error.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Consumer`2">
            <summary>
                Implements a high-level Apache Kafka consumer (with 
                key and value deserialization).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.KeyDeserializer">
            <summary>
                The IDeserializer implementation instance used to deserialize keys.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.ValueDeserializer">
            <summary>
                The IDeserializer implementation instance used to deserialize values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},Confluent.Kafka.Serialization.IDeserializer{`0},Confluent.Kafka.Serialization.IDeserializer{`1})">
            <summary>
                Creates a new Consumer instance.
            </summary>
            <param name="config">
                librdkafka configuration parameters (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)
            </param>
            <param name="keyDeserializer">
                An IDeserializer implementation instance for deserializing keys.
            </param>
            <param name="valueDeserializer">
                An IDeserializer implementation instance for deserializing values.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Consume(Confluent.Kafka.Message{`0,`1}@,System.Int32)">
            <summary>
                Poll for new messages / consumer events. Blocks until a new 
                message or event is ready to be handled or the timeout period
                <paramref name="millisecondsTimeout" /> has elapsed.
            </summary>
            <param name="message">
                A consumed message, or null if no messages are 
                available for consumption.
            </param>
            <param name="millisecondsTimeout">
                The maximum time to block (in milliseconds), or -1 to 
                block indefinitely. You should typically use a
                relatively short timout period because this operation
                cannot be cancelled.
            </param>
            <returns>
                true: a message (with non-error state) was consumed.
                false: no message was available for consumption.
            </returns>
            <remarks>
                Will invoke events for OnPartitionsAssigned/Revoked,
                OnOffsetsCommitted, OnConsumeError etc. on the calling 
                thread.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Consume(Confluent.Kafka.Message{`0,`1}@,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer`2.Consume(Confluent.Kafka.Message{`0,`1}@,System.Int32)" />.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Poll(System.Int32)">
            <summary>
                Poll for new consumer events, including new messages
                ready to be consumed (which will trigger the OnMessage
                event). Blocks until a new event is available to be 
                handled or the timeout period <paramref name="millisecondsTimeout" /> 
                has elapsed.
            </summary>
            <param name="millisecondsTimeout"> 
                The maximum time to block (in milliseconds), or -1 to 
                block indefinitely. You should typically use a
                relatively short timout period because this operation
                cannot be cancelled.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Poll(System.TimeSpan)">
            <summary>
                Poll for new consumer events, including new messages
                ready to be consumed (which will trigger the OnMessage
                event). Blocks until a new event is available to be
                handled or the timeout period <paramref name="timeout" /> 
                has elapsed.
            </summary>
            <param name="timeout"> 
                The maximum time to block. You should typically use a
                relatively short timout period because this operation
                cannot be cancelled.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Poll">
            <summary>
                Poll for new consumer events, including new messages
                ready to be consumed (which will trigger the OnMessage
                event).
            </summary> 
            <remarks>
                Blocks indefinitely until a new event is ready.
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnPartitionsAssigned">
            <summary>
                Raised on new partition assignment.
                You should typically call the Consumer.Assign method in this handler.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnPartitionsRevoked">
            <summary>
                Raised when a partition assignment is revoked.
                You should typically call the Consumer.Unassign method in this handler.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnOffsetsCommitted">
            <summary>
                Raised to report the result of (automatic) offset commits.
                Not raised as a result of the use of the CommitAsync method.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnLog">
             <summary>
                 Raised when there is information that should be logged.
             </summary>
             <remarks>
                 Note: By default not many log messages are generated.
             
                 You can specify one or more debug contexts using the 'debug'
                 configuration property and a log level using the 'log_level'
                 configuration property to enable more verbose logging,
                 however you shouldn't typically need to do this.
            
                 Warning: Log handlers are called spontaneously from internal librdkafka 
                 threads and the application must not call any Confluent.Kafka APIs from 
                 within a log handler or perform any prolonged operations.
             </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnStatistics">
            <summary>
                Raised on librdkafka statistics events. JSON formatted
                string as defined here: https://github.com/edenhill/librdkafka/wiki/Statistics
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnConsumeError">
            <summary>
                Raised when a consumed message has an error != NoError (both when Consume or Poll is used for polling).
                Also raised on deserialization errors.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnError">
            <summary>
                Raised on critical errors, e.g. connection failures or all 
                brokers down. Note that the client will try to automatically 
                recover from errors - these errors should be seen as 
                informational rather than catastrophic
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnPartitionEOF">
            <summary>
                Raised when the consumer reaches the end of a topic/partition it is reading from.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer`2.OnMessage">
            <summary>
                Raised when a new message is avaiable for consumption. NOT raised when Consumer.Consume
                is used for polling (only when Consmer.Poll is used for polling). NOT raised when the 
                message has an Error (OnConsumeError is raised in that case).
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Assignment">
            <summary>
                Gets the current partition assignment as set by Assign.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Subscription">
            <summary>
                Gets the current partition subscription as set by Subscribe.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Subscribe(System.Collections.Generic.IEnumerable{System.String})">
             <summary>
                 Update the subscription set to topics.
            
                 Any previous subscription will be unassigned and unsubscribed first.
            
                 The subscription set denotes the desired topics to consume and this
                 set is provided to the partition assignor (one of the elected group
                 members) for all clients which then uses the configured
                 partition.assignment.strategy to assign the subscription sets's
                 topics's partitions to the consumers, depending on their subscription.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Subscribe(System.String)">
             <summary>
                 Update the subscription set to a single topic.
            
                 Any previous subscription will be unassigned and unsubscribed first.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Unsubscribe">
            <summary>
                Unsubscribe from the current subscription set.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
             <summary>
                 Update the assignment set to <paramref name="partitions" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partitions">
                 The set of partitions to consume from. If an offset value of
                 Offset.Invalid (-1001) is specified for a partition, consumption
                 will resume from the last committed offset on that partition, or
                 according to the 'auto.offset.reset' configuration parameter if
                 no offsets have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 Update the assignment set to <paramref name="partitions" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partitions">
                 The set of partitions to consume from. Consumption will resume
                 from the last committed offset on each partition, or according
                 to the 'auto.offset.reset' configuration parameter if no offsets
                 have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Unassign">
            <summary>
                Stop consumption and remove the current assignment.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.StoreOffset(Confluent.Kafka.Message{`0,`1})">
            <summary>
                Store offsets for a single partition based on the topic/partition/offset
                of a message.
                
                The offset will be committed (written) to the offset store according
                to `auto.commit.interval.ms` or manual offset-less commit().
            </summary>
            <remarks>
                `enable.auto.offset.store` must be set to "false" when using this API.
            </remarks>
            <param name="message">
                A message used to determine the offset to store and topic/partition.
            </param>
            <returns>
                Current stored offset or a partition specific error.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.StoreOffsets(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
        Store offsets for one or more partitions. 
        
        The offset will be committed (written) to the offset store according
        to `auto.commit.interval.ms` or manual offset-less commit().
    </summary><remarks>
        `enable.auto.offset.store` must be set to "false" when using this API.
    </remarks><param name="offsets">
        List of offsets to be commited.
    </param><returns>
        For each topic/partition returns current stored offset
        or a partition specific error.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.CommitAsync">
            <summary>
                Commit offsets for the current assignment.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.CommitAsync(Confluent.Kafka.Message{`0,`1})">
            <summary>
                Commits an offset based on the topic/partition/offset of a message.
                The next message to be read will be that following <paramref name="message" />.
            </summary>
            <param name="message">
                The message used to determine the committed offset.
            </param>
            <remarks>
                A consumer which has position N has consumed records with offsets 0 through N-1 and will next receive the record with offset N.
                Hence, this method commits an offset of <paramref name="message" />.Offset + 1.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.CommitAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Commit an explicit list of offsets.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Dispose">
            <summary>
                Releases all resources used by this Consumer.
            
                This call will block until the consumer has revoked its assignment, 
                calling the rebalance event if it is configured, committed offsets to 
                broker, and left the consumer group.
            
                [UNSTABLE-API] - The Dispose method should not block. We will
                separate out consumer close functionality from this method.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Seek(Confluent.Kafka.TopicPartitionOffset)">
            <summary>
        Seek consumer for topic+partition to <parmref name="offset" /> which is either an
        absolute or logical offset. This must only be done for partitions that are 
        currently being consumed (i.e., have been Assign()ed). To set the start offset for 
        not-yet-consumed partitions you should use the 
        <see cref="M:Confluent.Kafka.Consumer.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})" /> 
        method instead.
    </summary><param name="tpo">
        The topic/partition to seek on and the offset to seek to.
    </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Pause(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
        Pause consumption for the provided list of partitions.
    </summary><param name="partitions">
        The partitions to pause consumption of.
    </param><returns>
        Per partition success or error.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Resume(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
        Resume consumption for the provided list of partitions.
    </summary><param name="partitions">
        The partitions to resume consumption of.
    </param><returns>
        Per partition success or error.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Committed(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition},System.TimeSpan)">
             <summary>
                 Retrieve current committed offsets for topics + partitions.
            
                 The offset field of each requested partition will be set to the offset
                 of the last consumed message, or RD_KAFKA_OFFSET_INVALID in case there was
                 no previous message, or, alternately a partition specific error may also be
                 returned.
            
                 throws KafkaException if there was a problem retrieving the above information.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.Position(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 Retrieve current positions (offsets) for topics + partitions.
            
                 The offset field of each requested partition will be set to the offset
                 of the last consumed message + 1, or RD_KAFKA_OFFSET_INVALID in case there was
                 no previous message, or, alternately a partition specific error may also be
                 returned.
            
                 throws KafkaException if there was a problem retrieving the above information.
             </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.Name">
            <summary>
                Gets the name of this consumer instance.
                Contains (but is not equal to) the client.id configuration parameter.
            </summary>
            <remarks>
                This name will be unique across all consumer instances
                in a given application which allows log messages to be
                associated with the corresponding instance.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Consumer`2.MemberId">
            <summary>
                Gets the (dynamic) group member id of this consumer (as set by
                the broker).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.ListGroups(System.TimeSpan)">
             <summary>
                 Get information pertaining to all groups in the Kafka cluster (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.ListGroup(System.String,System.TimeSpan)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.ListGroup(System.String)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.GetWatermarkOffsets(Confluent.Kafka.TopicPartition)">
             <summary>
                 Get last known low (oldest/beginning) and high (newest/end)
                 offsets for a topic/partition.
             
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <remarks>
                 The low offset is updated periodically (if statistics.interval.ms is set)
                 while the high offset is updated on each fetched message set from the 
                 broker.
            
                 If there is no cached offset (either low or high, or both) then
                 Offset.Invalid will be returned for the respective offset.
             </remarks>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.OffsetsForTimes(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionTimestamp},System.TimeSpan)">
            <summary>
        Look up the offsets for the given partitions by timestamp. The returned offset for each partition is the
        earliest offset whose timestamp is greater than or equal to the given timestamp in the corresponding partition.
    </summary><remarks>
        This is a blocking call. The consumer does not have to be assigned the partitions.
        If the message format version in a partition is before 0.10.0, i.e. the messages do not have timestamps, null
        will be returned for that partition.
        Note that this method may block indefinitely if the partition does not exist.
    </remarks><param name="timestampsToSearch">
        The mapping from partition to the timestamp to look up.
    </param><param name="timeout">
        The maximum period of time the call may block.
    </param><returns>
       A mapping from partition to the timestamp and offset of the first message with timestamp greater
       than or equal to the target timestamp. null will be returned for the partition if there is no such message.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.GetMetadata(System.Boolean,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.Int32)" /> for more information.
                
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.GetMetadata(System.Boolean)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.Int32)" /> for more information.
                
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer`2.AddBrokers(System.String)">
             <summary>
                 Adds one or more brokers to the Consumer's list of initial
                 bootstrap brokers. 
            
                 Note: Additional brokers are discovered automatically as 
                 soon as the Consumer connects to any broker by querying the 
                 broker metadata. Calling this method is only required in 
                 some scenarios where the address of all brokers in the 
                 cluster changes.
             </summary>
             <param name="brokers">
                 Coma-separated list of brokers in the same format as 
                 the bootstrap.server configuration parameter.
             </param>
             <remarks>
                 There is currently no API to remove existing configured, 
                 added or learnt brokers.
             </remarks>
             <returns>
                 The number of brokers added. This value includes brokers
                 that may have been specified a second time.
             </returns>
        </member>
        <member name="T:Confluent.Kafka.Consumer">
            <summary>
                Implements a high-level Apache Kafka consumer (without deserialization).
            
                [UNSTABLE-API] We are considering making this class private in a future version 
                so as to limit API surface area. Prefer to use the deserializing consumer
                <see cref="T:Confluent.Kafka.Consumer`2" /> where possible.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}})">
            <summary>
                Create a new consumer with the supplied configuration.
            </summary>
            <remarks>
                Refer to: https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnPartitionsAssigned">
            <summary>
                Raised on new partition assignment.
                You should typically call the Consumer.Assign method in this handler.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnPartitionsRevoked">
            <summary>
                Raised when a partition assignment is revoked.
                You should typically call the Consumer.Unassign method in this handler.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnOffsetsCommitted">
            <summary>
                Raised to report the result of (automatic) offset commits.
                Not raised as a result of the use of the CommitAsync method.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnError">
            <summary>
                Raised on critical errors, e.g. connection failures or all 
                brokers down. Note that the client will try to automatically 
                recover from errors - these errors should be seen as 
                informational rather than catastrophic
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnConsumeError">
            <summary>
                Raised when a consumed message has an error != NoError (both when Consume or Poll is used for polling).
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnStatistics">
            <summary>
                Raised on librdkafka statistics events. JSON formatted
                string as defined here: https://github.com/edenhill/librdkafka/wiki/Statistics
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnLog">
            <summary>
                Raised when there is information that should be logged.
            </summary>
            <remarks>
                Note: By default not many log messages are generated.
            
                You can specify one or more debug contexts using the 'debug'
                configuration property and a log level using the 'log_level'
                configuration property to enable more verbose logging,
                however you shouldn't typically need to do this.
            
                Warning: Log handlers are called spontaneously from internal librdkafka 
                threads and the application must not call any Confluent.Kafka APIs from 
                within a log handler or perform any prolonged operations.
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnMessage">
            <summary>
                Raised when a new message is avaiable for consumption. NOT raised when Consumer.Consume
                is used for polling (only when Consmer.Poll is used for polling). NOT raised when the 
                message has an Error (OnConsumeError is raised in that case).
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Consumer.OnPartitionEOF">
            <summary>
                Raised when the consumer reaches the end of a topic/partition it is reading from.
            </summary>
            <remarks>
                Executes on the same thread as every other Consumer event handler (except OnLog which may be called from an arbitrary thread).
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Consumer.Assignment">
            <summary>
                Gets the current partition assignment as set by Assign.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer.Subscription">
            <summary>
                Gets the current topic subscription as set by Subscribe.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Subscribe(System.Collections.Generic.IEnumerable{System.String})">
             <summary>
                 Update the subscription set to topics.
            
                 Any previous subscription will be unassigned and unsubscribed first.
            
                 The subscription set denotes the desired topics to consume and this
                 set is provided to the partition assignor (one of the elected group
                 members) for all clients which then uses the configured
                 partition.assignment.strategy to assign the subscription sets's
                 topics's partitions to the consumers, depending on their subscription.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Subscribe(System.String)">
             <summary>
                 Update the subscription set to a single topic.
            
                 Any previous subscription will be unassigned and unsubscribed first.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Unsubscribe">
            <summary>
                Unsubscribe from the current subscription set.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
             <summary>
                 Update the assignment set to <paramref name="partitions" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partitions">
                 The set of partitions to consume from. If an offset value of
                 Offset.Invalid (-1001) is specified for a partition, consumption
                 will resume from the last committed offset on that partition, or
                 according to the 'auto.offset.reset' configuration parameter
                 if no offsets have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 Update the assignment set to <paramref name="partitions" />.
            
                 The assignment set is the complete set of partitions to consume
                 from and will replace any previous assignment.
             </summary>
             <param name="partitions">
                 The set of partitions to consume from. Consumption will resume
                 from the last committed offset on each partition, or according
                 to the 'auto.offset.reset' configuration parameter if no offsets
                 have been committed yet.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Unassign">
            <summary>
                Stop consumption and remove the current topic/partition assignment.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Consume(Confluent.Kafka.Message@,System.Int32)">
            <summary>
                Poll for new messages / consumer events. Blocks until a new 
                message or event is ready to be handled or the timeout period
                <paramref name="millisecondsTimeout" /> has elapsed.
            </summary>
            <param name="message">
                A consumed message, or null if no messages are 
                available for consumption.
            </param>
            <param name="millisecondsTimeout">
                The maximum time to block (in milliseconds), or -1 to 
                block indefinitely. You should typically use a
                relatively short timout period because this operation
                cannot be cancelled.
            </param>
            <returns>
                true: a message (with non-error state) was consumed.
                false: no message was available for consumption.
            </returns>
            <remarks>
                Will invoke events for OnPartitionsAssigned/Revoked,
                OnOffsetsCommitted, OnConsumeError etc. on the calling 
                thread.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Consume(Confluent.Kafka.Message@,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Consumer.Consume(Confluent.Kafka.Message@,System.Int32)" />
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Poll(System.TimeSpan)">
            <summary>
                Poll for new consumer events, including new messages
                ready to be consumed (which will trigger the OnMessage
                event).
            </summary>
            <param name="timeout"> 
                The maximum time to block. You should typically use a
                relatively short timout period because this operation
                cannot be cancelled.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Poll(System.Int32)">
            <summary>
                Poll for new consumer events, including new messages
                ready to be consumed (which will trigger the OnMessage
                event). Blocks until a new event is available to be 
                handled or the timeout period <paramref name="millisecondsTimeout" /> 
                has elapsed.
            </summary>
            <param name="millisecondsTimeout"> 
                The maximum time to block (in milliseconds), or -1 to 
                block indefinitely. You should typically use a
                relatively short timout period because this operation
                cannot be cancelled.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Poll">
            <summary>
                Poll for new consumer events, including new messages
                ready to be consumed (which will trigger the OnMessage
                event).
            </summary> 
            <remarks>
                Blocks indefinitely until a new event is ready.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Consumer.StoreOffsets(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
        Store offsets for one or more partitions. 
        
        The offset will be committed (written) to the offset store according
        to `auto.commit.interval.ms` or manual offset-less commit().
    </summary><remarks>
        `enable.auto.offset.store` must be set to "false" when using this API.
    </remarks><param name="offsets">
        List of offsets to be commited.
    </param><returns>
        For each topic/partition returns current stored offset
        or a partition specific error.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.CommitAsync">
            <summary>
                Commit offsets for the current assignment.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.CommitAsync(Confluent.Kafka.Message)">
            <summary>
                Commits an offset based on the topic/partition/offset of a message.
                The next message to be read will be that following <paramref name="message" />.
            </summary>
            <param name="message">
                The message used to determine the committed offset.
            </param>
            <remarks>
                A consumer which has position N has consumed records with offsets 0 through N-1 and will next receive the record with offset N.
                Hence, this method commits an offset of <paramref name="message" />.Offset + 1.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Consumer.CommitAsync(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Commit an explicit list of offsets.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Seek(Confluent.Kafka.TopicPartitionOffset)">
            <summary>
        Seek consumer for topic+partition to <parmref name="offset" /> which is either an
        absolute or logical offset. This must only be done for partitions that are 
        currently being consumed (i.e., have been Assign()ed). To set the start offset for 
        not-yet-consumed partitions you should use the 
        <see cref="M:Confluent.Kafka.Consumer.Assign(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})" /> 
        method instead.
    </summary><param name="tpo">
        The topic/partition to seek on and the offset to seek to.
    </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Pause(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
        Pause consumption for the provided list of partitions.
    </summary><param name="partitions">
        The partitions to pause consumption of.
    </param><returns>
        Per partition success or error.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Resume(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
            <summary>
        Resume consumption for the provided list of partitions.
    </summary><param name="partitions">
        The partitions to resume consumption of.
    </param><returns>
        Per partition success or error.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Committed(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition},System.TimeSpan)">
             <summary>
                 Retrieve current committed offsets for topics + partitions.
            
                 The offset field of each requested partition will be set to the offset
                 of the last consumed message, or RD_KAFKA_OFFSET_INVALID in case there was
                 no previous message, or, alternately a partition specific error may also be
                 returned.
            
                 throws KafkaException if there was a problem retrieving the above information.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Position(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 Retrieve current positions (offsets) for topics + partitions.
            
                 The offset field of each requested partition will be set to the offset
                 of the last consumed message + 1, or RD_KAFKA_OFFSET_INVALID in case there was
                 no previous message, or, alternately a partition specific error may also be
                 returned.
            
                 throws KafkaException if there was a problem retrieving the above information.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.Dispose">
            <summary>
                Releases all resources used by this Consumer.
            
                This call will block until the consumer has revoked its assignment, 
                calling the rebalance event if it is configured, committed offsets to 
                broker, and left the consumer group.
            
                [UNSTABLE-API] - The Dispose method should not block. We will
                separate out consumer close functionality from this method.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Consumer.Name">
            <summary>
                Gets the name of this consumer instance.
                Contains (but is not equal to) the client.id configuration parameter.
            </summary>
            <remarks>
                This name will be unique across all consumer instances
                in a given application which allows log messages to be
                associated with the corresponding instance.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Consumer.MemberId">
            <summary>
                Gets the (dynamic) group member id of this consumer (as set by
                the broker).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.ListGroups(System.TimeSpan)">
             <summary>
                 Get information pertaining to all groups in the Kafka cluster (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Consumer.ListGroup(System.String,System.TimeSpan)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.ListGroup(System.String)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.GetWatermarkOffsets(Confluent.Kafka.TopicPartition)">
             <summary>
                 Get last known low (oldest/beginning) and high (newest/end)
                 offsets for a topic/partition.
                 
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <remarks>
                 The low offset is updated periodically (if statistics.interval.ms is set)
                 while the high offset is updated on each fetched message set from the broker.
            
                 If there is no cached offset (either low or high, or both) then
                 Offset.Invalid will be returned for the respective offset.
             </remarks>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.OffsetsForTimes(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionTimestamp},System.TimeSpan)">
            <summary>
        Look up the offsets for the given partitions by timestamp. The returned offset for each partition is the
        earliest offset whose timestamp is greater than or equal to the given timestamp in the corresponding partition.
    </summary><remarks>
        This is a blocking call. The consumer does not have to be assigned the partitions.
        If the message format version in a partition is before 0.10.0, i.e. the messages do not have timestamps, null
        will be returned for that partition.
        Note that this method may block indefinitely if the partition does not exist.
    </remarks><param name="timestampsToSearch">
        The mapping from partition to the timestamp to look up.
    </param><param name="timeout">
        The maximum period of time the call may block.
    </param><returns>
       A mapping from partition to the timestamp and offset of the first message with timestamp greater
       than or equal to the target timestamp. null will be returned for the partition if there is no such message.
    </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocking)
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Consumer.GetMetadata(System.Boolean,System.TimeSpan)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.Int32)" /> for more information.
                
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.GetMetadata(System.Boolean)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.Int32)" /> for more information.
                
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Consumer.AddBrokers(System.String)">
             <summary>
                 Adds one or more brokers to the Consumer's list of initial
                 bootstrap brokers. 
            
                 Note: Additional brokers are discovered automatically as 
                 soon as the Consumer connects to any broker by querying the 
                 broker metadata. Calling this method is only required in 
                 some scenarios where the address of all brokers in the 
                 cluster changes.
             </summary>
             <param name="brokers">
                 Coma-separated list of brokers in the same format as 
                 the bootstrap.server configuration parameter.
             </param>
             <remarks>
                 There is currently no API to remove existing configured, 
                 added or learnt brokers.
             </remarks>
             <returns>
                 The number of brokers added. This value includes brokers
                 that may have been specified a second time.
             </returns>
        </member>
        <member name="T:Confluent.Kafka.Error">
            <summary>
                Represents an error that occured when interacting with a
                Kafka broker or the librdkafka library.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Error.#ctor(Confluent.Kafka.ErrorCode)">
            <summary>
                Initialize a new Error instance from a particular
                <see cref="T:Confluent.Kafka.ErrorCode"/> value.
            </summary>
            <param name="code">
                The <see cref="T:Confluent.Kafka.ErrorCode"/> value associated with this Error.
            </param>
            <remarks>
                The reason string associated with this Error will
                be a static value associated with the <see cref="T:Confluent.Kafka.ErrorCode"/>.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Error.#ctor(Confluent.Kafka.ErrorCode,System.String)">
            <summary>
                Initialize a new Error instance from a particular
                <see cref="T:Confluent.Kafka.ErrorCode"/> value and custom <paramref name="reason"/>
                string.
            </summary>
            <param name="code">
                The <see cref="T:Confluent.Kafka.ErrorCode"/> value associated with this Error.
            </param>
            <param name="reason">
                A custom reason string associated with the error
                (overriding the static string associated with 
                <paramref name="code"/>).
            </param>
        </member>
        <member name="P:Confluent.Kafka.Error.Code">
            <summary>
                Gets the <see cref="T:Confluent.Kafka.ErrorCode"/> associated with this Error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.Reason">
            <summary>
                Gets a human readable reason string associated with this error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.HasError">
            <summary>
                true if Code != ErrorCode.NoError.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.IsLocalError">
            <summary>
                true if this is error originated locally (within librdkafka), false otherwise.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Error.IsBrokerError">
            <summary>
                true if this error originated on a broker, false otherwise.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Implicit(Confluent.Kafka.Error)~System.Boolean">
            <summary>
                Converts the specified Error value to a boolean value (false if e.Code == ErrorCode.NoError, true otherwise).
            </summary>
            <param name="e">
                The Error value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Implicit(Confluent.Kafka.Error)~Confluent.Kafka.ErrorCode">
            <summary>
                Converts the specified Error value to the value of it's Code property.
            </summary>
            <param name="e">
                The Error value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Implicit(Confluent.Kafka.ErrorCode)~Confluent.Kafka.Error">
            <summary>
                Converts the specified <see cref="T:Confluent.Kafka.ErrorCode"/> value to it's corresponding rich Error value.
            </summary>
            <param name="c">
                The <see cref="T:Confluent.Kafka.ErrorCode"/> value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Error.Equals(System.Object)">
            <summary>
                Tests whether this Error instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is an Error and the Code property values are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.GetHashCode">
            <summary>
                Returns a hash code for this Error value.
            </summary>
            <returns>
                An integer that specifies a hash value for this Error value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Equality(Confluent.Kafka.Error,Confluent.Kafka.Error)">
            <summary>
                Tests whether Error value a is equal to Error value b.
            </summary>
            <param name="a">
                The first Error value to compare.
            </param>
            <param name="b">
                The second Error value to compare.
            </param>
            <returns>
                true if Error values a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.op_Inequality(Confluent.Kafka.Error,Confluent.Kafka.Error)">
            <summary>
                Tests whether Error value a is not equal to Error value b.
            </summary>
            <param name="a">
                The first Error value to compare.
            </param>
            <param name="b">
                The second Error value to compare.
            </param>
            <returns>
                true if Error values a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Error.ToString">
            <summary>
                Returns the string representation of the error.
                Depending on error source this might be a rich
                contextual error message, or a simple static
                string representation of the error Code.
            </summary>
            <returns>
                A string representation of the Error object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.ErrorCode">
            <summary>
                Enumeration of local and broker generated error codes.
            </summary>
            <remarks>
                Error codes that relate to locally produced errors in 
                librdkafka are prefixed with Local_
            </remarks>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_BadMsg">
            <summary>
                Received message is incorrect
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_BadCompression">
            <summary>
                Bad/unknown compression
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Destroy">
            <summary>
                Broker is going away
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Fail">
            <summary>
                Generic failure
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Transport">
            <summary>
                Broker transport failure
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_CritSysResource">
            <summary>
                Critical system resource
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Resolve">
            <summary>
                Failed to resolve broker
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_MsgTimedOut">
            <summary>
                Produced message timed out
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_PartitionEOF">
            <summary>
                Reached the end of the topic+partition queue on the broker. Not really an error.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownPartition">
            <summary>
                Permanent: Partition does not exist in cluster.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_FS">
            <summary>
                File or filesystem error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownTopic">
            <summary>
                Permanent: Topic does not exist in cluster.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_AllBrokersDown">
            <summary>
                All broker connections are down.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_InvalidArg">
            <summary>
                Invalid argument, or invalid configuration
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_TimedOut">
            <summary>
                Operation timed out
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_QueueFull">
            <summary>
                Queue is full
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_IsrInsuff">
            <summary>
                ISR count &lt; required.acks
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NodeUpdate">
            <summary>
                Broker node update
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Ssl">
            <summary>
                SSL error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_WaitCoord">
            <summary>
                Waiting for coordinator to become available.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownGroup">
            <summary>
                Unknown client group
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_InProgress">
            <summary>
                Operation in progress
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_PrevInProgress">
            <summary>
                Previous operation in progress, wait for it to finish.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ExistingSubscription">
            <summary>
                This operation would interfere with an existing subscription
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_AssignPartitions">
            <summary>
                Assigned partitions (rebalance_cb)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_RevokePartitions">
            <summary>
                Revoked partitions (rebalance_cb)
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Conflict">
            <summary>
                Conflicting use
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_State">
            <summary>
                Wrong state
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnknownProtocol">
            <summary>
                Unknown protocol
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NotImplemented">
            <summary>
                Not implemented
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Authentication">
            <summary>
                Authentication failure
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_NoOffset">
            <summary>
                No stored offset
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Outdated">
            <summary>
                Outdated
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_TimedOutQueue">
            <summary>
                Timed out in queue
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_UnsupportedFeature">
            <summary>
                Feature not supported by broker
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_WaitCache">
            <summary>
                Awaiting cache update
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_Intr">
            <summary>
                Operation interrupted
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_KeySerialization">
            <summary>
                Key serialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ValueSerialization">
            <summary>
                Value serialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_KeyDeserialization">
            <summary>
                Key deserialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Local_ValueDeserialization">
            <summary>
                Value deserialization error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.Unknown">
            <summary>
                Unknown broker error
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NoError">
            <summary>
                Success
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.OffsetOutOfRange">
            <summary>
                Offset out of range
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidMsg">
            <summary>
                Invalid message
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnknownTopicOrPart">
            <summary>
                Unknown topic or partition
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidMsgSize">
            <summary>
                Invalid message size
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.LeaderNotAvailable">
            <summary>
                Leader not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotLeaderForPartition">
            <summary>
                Not leader for partition
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.RequestTimedOut">
            <summary>
                Request timed out
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.BrokerNotAvailable">
            <summary>
                Broker not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.ReplicaNotAvailable">
            <summary>
                Replica not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.MsgSizeTooLarge">
            <summary>
                Message size too large
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.StaleCtrlEpoch">
            <summary>
                StaleControllerEpochCode
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.OffsetMetadataTooLarge">
            <summary>
                Offset metadata string too large
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NetworkException">
            <summary>
                Broker disconnected before response received
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.GroupLoadInProress">
            <summary>
                Group coordinator load in progress
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.GroupCoordinatorNotAvailable">
            <summary>
            Group coordinator not available
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotCoordinatorForGroup">
            <summary>
                Not coordinator for group
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TopicException">
            <summary>
                Invalid topic
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.RecordListTooLarge">
            <summary>
                Message batch larger than configured server segment size
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotEnoughReplicas">
            <summary>
                Not enough in-sync replicas
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.NotEnoughReplicasAfterAppend">
            <summary>
                Message(s) written to insufficient number of in-sync replicas
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidRequiredAcks">
            <summary>
                Invalid required acks value
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.IllegalGeneration">
            <summary>
                Specified group generation id is not valid
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InconsistentGroupProtocol">
            <summary>
                Inconsistent group protocol
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidGroupId">
            <summary>
                Invalid group.id
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnknownMemberId">
            <summary>
                Unknown member
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidSessionTimeout">
            <summary>
                Invalid session timeout
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.RebalanceInProgress">
            <summary>
                Group rebalance in progress
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidCommitOffsetSize">
            <summary>
                Commit offset data size is not valid
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.TopicAuthorizationFailed">
            <summary>
                Topic authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.GroupAuthorizationFailed">
            <summary>
                Group authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.ClusterAuthorizationFailed">
            <summary>
                Cluster authorization failed
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.InvalidTimestamp">
            <summary>
                Invalid timestamp
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnsupportedSaslMechanism">
            <summary>
                Unsupported SASL mechanism
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.IllegalSaslState">
            <summary>
                Illegal SASL state
            </summary>
        </member>
        <member name="F:Confluent.Kafka.ErrorCode.UnsupportedVersion">
            <summary>
                Unuspported version
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ErrorCodeExtensions">
            <summary>
                Provides extension methods on the ErrorCode enumeration.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ErrorCodeExtensions.GetReason(Confluent.Kafka.ErrorCode)">
            <summary>
                Returns the static error string associated with 
                the particular ErrorCode value.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.GroupInfo">
            <summary>
                Encapsulates information describing a particular
                Kafka group.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.GroupInfo.#ctor(Confluent.Kafka.BrokerMetadata,System.String,Confluent.Kafka.Error,System.String,System.String,System.String,System.Collections.Generic.List{Confluent.Kafka.GroupMemberInfo})">
            <summary>
                Initializes a new instance of the GroupInfo class.
            </summary>
            <param name="broker">
                Originating broker info.
            </param>
            <param name="group">
                The group name.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.GroupInfo.Error"/> value associated with the information encapsulated by this class.
            </param>
            <param name="state">
                The group state.
            </param>
            <param name="protocolType">
                The group protocol type.
            </param>
            <param name="protocol">
                The group protocol.
            </param>
            <param name="members">
                The group members.
            </param>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Broker">
            <summary>
                Gets the originating-broker info.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Group">
            <summary>
                Gets the group name
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Error">
            <summary>
                Gets a rich <see cref="P:Confluent.Kafka.GroupInfo.Error"/> value associated with the information encapsulated by this class.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.State">
            <summary>
                Gets the group state
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.ProtocolType">
            <summary>
                Gets the group protocol type
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Protocol">
            <summary>
                Gets the group protocol
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupInfo.Members">
            <summary>
                Gets the group members
            </summary>
        </member>
        <member name="T:Confluent.Kafka.GroupMemberInfo">
            <summary>
                Encapsulates information describing a particular
                member of a Kafka group.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.GroupMemberInfo.#ctor(System.String,System.String,System.String,System.Byte[],System.Byte[])">
            <summary>
                Initializes a new GroupMemberInfo class instance.
            </summary>
            <param name="memberId">
                The member id (generated by the broker).
            </param>
            <param name="clientId">
                The client's client.id.
            </param>
            <param name="clientHost">
                The client's hostname.
            </param>
            <param name="memberMetadata">
                Gets the member metadata (binary). The format of this data depends on the protocol type.
            </param>
            <param name="memberAssignment">
                Gets the member assignment (binary). The format of this data depends on the protocol type.
            </param>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.MemberId">
            <summary>
                Gets the member id (generated by broker).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.ClientId">
            <summary>
                Gets the client's client.id.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.ClientHost">
            <summary>
                Gets the client's hostname.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.MemberMetadata">
            <summary>
                Gets the member metadata (binary). The format of this data depends on the protocol type.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.GroupMemberInfo.MemberAssignment">
            <summary>
                Gets the member assignment (binary). The format of this data depends on the protocol type.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.IDeliveryHandler">
            <summary>
                This interface is implemented by types that handle delivery report
                callbacks as a result of calls to Confluent.Kafka.Producer.ProduceAsync().
            </summary>
            <remarks>
                Methods of this interface will be executed on the poll thread and will
                block other operations - consider this when implementing.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.IDeliveryHandler.MarshalData">
            <summary>
                Gets whether or not to marshal key and value data 
                from librdkafka when the delivery report is 
                available. Usually this should return true.
                Return false for a small performance improvement
                if you don't need this information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IDeliveryHandler.HandleDeliveryReport(Confluent.Kafka.Message)">
            <summary>
                This method is called when the delivery report
                is available
            </summary>
            <param name="message">
                The delivery report.
            </param>
        </member>
        <member name="T:Confluent.Kafka.IDeliveryHandler`2">
            <summary>
                This interface is implemented by types that handle delivery report
                callbacks as a result of calls to Confluent.Kafka.Producer&lt;TKey,TValue&gt;.ProduceAsync().
            </summary>
            <remarks>
                Methods of this interface will be executed on the poll thread and will
                block other operations - consider this when implementing.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.IDeliveryHandler`2.MarshalData">
            <summary>
                Gets whether or not to marshal key and value data 
                from librdkafka when the delivery report is 
                available. Usually this should return true.
                Return false for a small performance improvement
                if you don't need this information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.IDeliveryHandler`2.HandleDeliveryReport(Confluent.Kafka.Message{`0,`1})">
            <summary>
                This method is called when the delivery report
                is available
            </summary>
            <param name="message">
                The delivery report.
            </param>
        </member>
        <member name="T:Confluent.Kafka.Ignore">
            <summary>
                A type for use in conjunction with <see cref="T:Confluent.Kafka.Serialization.IgnoreDeserializer" />
                that enables message keys or values to be read as null, regardless
                of their value.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Impl.LibRdKafka.ProduceVarTag">
            <summary>
                Var-arg tag types, used in producev
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Impl.NativeMethods.NativeMethods">
            <summary>
                This class should be an exact replica of other NativeMethods classes, except
                for the DllName const.
            </summary>
            <remarks>
                This copy/pasting is required because DllName must be const. 
                TODO: generate the NativeMethods classes at runtime (compile C# code) rather
                than copy/paste.
            
                Alternatively, we could have used dlopen to load the native library, but to 
                do that we need to know the absolute path of the native libraries because the
                dlopen call does not know .NET runtime library storage conventions. Unfortunately 
                these are relatively complex, so we prefer to go with the copy/paste solution
                which is relatively simple.
            </remarks>
        </member>
        <member name="T:Confluent.Kafka.Impl.NativeMethods.NativeMethods_Debian9">
            <summary>
                This class should be an exact replica of other NativeMethods classes, except
                for the DllName const.
            </summary>
            <remarks>
                This copy/pasting is required because DllName must be const. 
                TODO: generate the NativeMethods classes at runtime (compile C# code) rather
                than copy/paste.
            
                Alternatively, we could have used dlopen to load the native library, but to 
                do that we need to know the absolute path of the native libraries because the
                dlopen call does not know .NET runtime library storage conventions. Unfortunately 
                these are relatively complex, so we prefer to go with the copy/paste solution
                which is relatively simple.
            </remarks>
        </member>
        <member name="F:Confluent.Kafka.Impl.ConfRes.Unknown">
            <summary>
                Unknown configuration name.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Impl.ConfRes.Invalid">
            <summary>
                Invalid configuration value.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Impl.ConfRes.Ok">
            <summary>
                Configuration okay
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeHandleZeroIsInvalid.ThrowIfHandleClosed">
            <summary>
                Prevent AccessViolationException when handle has already been closed.
                Should be called at start of every function using handle,
                except in ReleaseHandle.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.Topic(System.String,System.IntPtr)">
            <summary>
                Setting the config parameter to IntPtr.Zero returns the handle of an 
                existing topic, or an invalid handle if a topic with name <paramref name="topic" /> 
                does not exist. Note: Only the first applied configuration for a specific
                topic will be used.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.GetMetadata(System.Boolean,Confluent.Kafka.Impl.SafeTopicHandle,System.Int32)">
            <summary>
                - allTopics=true - request all topics from cluster
                - allTopics=false, topic=null - request only locally known topics (topic_new():ed topics or otherwise locally referenced once, such as consumed topics)
                - allTopics=false, topic=valid - request specific topic
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.StoreOffsets(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
                Store offsets for one or more partitions.
              
                The offset will be committed (written) to the offset store according
                to `auto.commit.interval.ms` or manual offset-less commit().
            </summary>
            <remarks>
                `enable.auto.offset.store` must be set to "false" when using this API.
            </remarks>
            <param name="offsets">
                List of offsets to be commited.
            </param>
            <returns>
                For each topic/partition returns current stored offset
                or a partition specific error.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.dummyOffsetCommitCb(System.IntPtr,Confluent.Kafka.ErrorCode,System.IntPtr,System.IntPtr)">
            <summary>
             Dummy commit callback that does nothing but prohibits
             triggering the global offset_commit_cb.
             Used by manual commits.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.commitSync(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
            Manual sync commit, will block indefinately.
            </summary>
            <param name="offsets">Offsets to commit, or null for current assignment.</param>
            <returns>CommittedOffsets with global or per-partition errors.</returns>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.Committed(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition},System.IntPtr)">
             <summary>
                 for each topic/partition returns the current committed offset
                 or a partition specific error. if no stored offset, Offset.Invalid.
            
                 throws KafkaException if the above information cannot be retrieved.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.Position(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartition})">
             <summary>
                 for each topic/partition returns the current position (last consumed offset + 1)
                 or a partition specific error.
            
                 throws KafkaException if the above information cannot be retrieved.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Impl.SafeKafkaHandle.GetCTopicPartitionList(System.Collections.Generic.IEnumerable{Confluent.Kafka.TopicPartitionOffset})">
            <summary>
            Creates and returns a C rd_kafka_topic_partition_list_t * populated by offsets.
            </summary>
            <returns>
            If offsets is null a null IntPtr will be returned, else a IntPtr
            which must destroyed with LibRdKafka.topic_partition_list_destroy()
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Impl.SafeTopicHandle">
            <remarks>
                TODO: remove when get_metadata works with string for only_topic
            </remarks>
        </member>
        <member name="T:Confluent.Kafka.StringExtensions">
            <summary>
                Extension methods for the <see cref="T:System.String"/> class.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.TimeSpanExtensions">
            <summary>
                Extension methods for the <see cref="T:System.TimeSpan"/> class.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TimeSpanExtensions.TotalMillisecondsAsInt(System.TimeSpan)">
            <summary>
                Converts the TimeSpan value <paramref name="timespan" /> to an integer number of milliseconds.
                An <see cref="T:System.OverflowException"/> is thrown if the number of milliseconds is greater than Int32.MaxValue.
            </summary>
            <param name="timespan">
                The TimeSpan value to convert to milliseconds.
            </param>
            <returns>
                The TimeSpan value <paramref name="timespan" /> in milliseconds.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Internal.SafeDictionary`2">
            <summary>
                A minimal Dictionary implementation with the following properties:
                    1. all access is thread safe.
                    2. grows unbounded (elements cannot be removed or overwritten).
                    3. reads are fast (no locking).
                    4. writes are slow (locking).
                    5. is Disposable (+ values must themselves be Disposable).
            </summary>
            <remarks>
                The container takes ownership of any resources placed in it. This is
                a little atypical, but it avoids the need to expose a means for the
                caller to iterate through the elements, which is difficult to do in
                a thread safe way.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Internal.Util.Marshal.PtrToStringUTF8(System.IntPtr)">
            <summary>
                Interpret a zero terminated c string as UTF-8.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.ISerializingProducer`2">
            <summary>
                This interface describes the minimum functionality
                to be provided by a high level (serializing) Kafka 
                producer.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ISerializingProducer`2.Name">
            <summary>
                Gets the name of the underlying producer instance.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ISerializingProducer`2.KeySerializer">
            <summary>
                Gets the ISerializer implementation instance used to serialize keys.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.ISerializingProducer`2.ValueSerializer">
            <summary>
                Gets the ISerializer implementation instance used to serialize values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1)"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,System.Int32)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32)"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,System.Boolean)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Boolean)"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,Confluent.Kafka.IDeliveryHandler{`0,`1})"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,System.Int32,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,Confluent.Kafka.IDeliveryHandler{`0,`1})"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.ISerializingProducer`2.ProduceAsync(System.String,`0,`1,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})"/>.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.KafkaException">
            <summary>
                Represents an error that occured during an interaction with Kafka.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.KafkaException.#ctor(Confluent.Kafka.Error)">
            <summary>
                Initialize a new instance of KafkaException based on 
                an existing Error instance.
            </summary>
            <param name="error"> 
                The Kafka Error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.KafkaException.#ctor(Confluent.Kafka.Error,System.Exception)">
            <summary>
                Initialize a new instance of KafkaException based on
                an existing Error instance and inner exception.
            </summary>
            <param name="error">
                The Kafka Error.
            </param>
            <param name="innerException">
                The exception instance that caused this exception.
            </param>
        </member>
        <member name="M:Confluent.Kafka.KafkaException.#ctor(Confluent.Kafka.ErrorCode)">
            <summary>
                Initialize a new instance of KafkaException based on 
                an existing ErrorCode value.
            </summary>
            <param name="code"> 
                The Kafka ErrorCode.
            </param>
        </member>
        <member name="P:Confluent.Kafka.KafkaException.Error">
            <summary>
                Gets the Error associated with this KafkaException.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Library">
            <summary>
                Methods that relate to the native librdkafka library itself
                (do not require a Producer or Consumer broker connection).
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.Version">
             <summary>
                 Gets the librdkafka version as an integer.
            
                 Interpreted as hex MM.mm.rr.xx:
                     - MM = Major
                     - mm = minor
                     - rr = revision
                     - xx = pre-release id (0xff is the final release)
            
                 E.g.: 0x000901ff = 0.9.1
             </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.VersionString">
            <summary>
                Gets the librdkafka version as string.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.DebugContexts">
            <summary>
                Gets a list of the supported debug contexts.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Library.IsLoaded">
            <summary>
                true if librdkafka has been successfully loaded, false if not.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Library.Load">
            <summary>
                Loads the native librdkafka library. Does nothing if the library is
                already loaded.
            </summary>
            <returns>
                true if librdkafka was loaded as a result of this call, false if the
                library has already been loaded.
            </returns>
            <remarks>
                You will not typically need to call this method - librdkafka is loaded
                automatically on first use of a Producer or Consumer instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Library.Load(System.String)">
            <summary>
                Loads the native librdkafka library from the specified path. Does 
                nothing if the library is already loaded.
            </summary>
            <returns>
                true if librdkafka was loaded as a result of this call, false if the
                library has already been loaded.
            </returns>
            <remarks>
                You will not typically need to call this method - librdkafka is loaded
                automatically on first use of a Producer or Consumer instance.
            </remarks>
        </member>
        <member name="T:Confluent.Kafka.Loggers">
            <summary>
                OnLog callback event handler implementations.
            </summary>
            <remarks>
                Warning: Log handlers are called spontaneously from internal librdkafka 
                threads and the application must not call any Confluent.Kafka APIs from 
                within a log handler or perform any prolonged operations.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Loggers.ConsoleLogger(System.Object,Confluent.Kafka.LogMessage)">
            <summary>
                The method used to log messages by default.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.LogMessage">
            <summary>
                Encapsulates information provided to the 
                Producer/Consumer OnLog event.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.LogMessage.#ctor(System.String,System.Int32,System.String,System.String)">
            <summary>
                Instantiates a new LogMessage class instance.
            </summary> 
            <param name="name">
                The librdkakfa client instance name.
            </param>
            <param name="level">
                The log level (levels correspond to syslog(3)), lower is worse.
            </param>
            <param name="facility">
                The facility (section of librdkafka code) that produced the message.
            </param>
            <param name="message">
                The log message.
            </param>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Name">
            <summary>
                Gets the librdkafka client instance name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Level">
            <summary>
                Gets the log level (levels correspond to syslog(3)), lower is worse.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Facility">
            <summary>
                Gets the facility (section of librdkafka code) that produced the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.LogMessage.Message">
            <summary>
                Gets the log message.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Message`2">
            <summary>
                Represents a (deserialized) message stored in Kafka.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Message`2.#ctor(System.String,System.Int32,System.Int64,`0,`1,Confluent.Kafka.Timestamp,Confluent.Kafka.Error)">
            <summary>
                Instantiates a new Message class instance.
            </summary>
            <param name="topic">
                The Kafka topic name associated with this message.
            </param>
            <param name="partition">
                The topic partition id associated with this message.
            </param>
            <param name="offset">
                The offset of this message in the Kafka topic partition.
            </param>
            <param name="key">
                The message key value.
            </param>
            <param name="val">
                The message value.
            </param>
            <param name="timestamp">
                The message timestamp.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.Message`2.Error"/> associated with the message.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Topic">
            <summary>
                Gets the topic name associated with this message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Partition">
            <summary>
                Gets the partition associated with this message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Offset">
            <summary>
                Gets the offset of this message in the Kafka topic partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Key">
            <summary>
                Gets the message key value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Value">
            <summary>
                Gets the message value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Timestamp">
            <summary>
                Gets the message timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.Error">
            <summary>
                Gets a rich <see cref="P:Confluent.Kafka.Message`2.Error"/> associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.TopicPartitionOffset">
            <summary>
                Gets the topic/partition/offset associated with this message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message`2.TopicPartition">
            <summary>
                Gets the topic/partition associated with this message.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Message">
            <summary>
                Represents a message stored in Kafka.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Message.#ctor(System.String,System.Int32,System.Int64,System.Byte[],System.Byte[],Confluent.Kafka.Timestamp,Confluent.Kafka.Error)">
            <summary>
                Instantiates a new Message class instance.
            </summary>
            <param name="topic">
                The Kafka topic name associated with this message.
            </param>
            <param name="partition">
                The topic partition id associated with this message.
            </param>
            <param name="offset">
                The offset of this message in the Kafka topic partition.
            </param>
            <param name="key">
                The message key value.
            </param>
            <param name="val">
                The message value.
            </param>
            <param name="timestamp">
                The message timestamp.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.Message.Error"/> associated with the message.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Message.Topic">
            <summary>
                Gets the Kafka topic name associated with this message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Partition">
            <summary>
                Gets the topic partition associated with this message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Offset">
            <summary>
                Gets the offset of this message in the Kafka topic partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Value">
            <summary>
                Gets the message value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Key">
            <summary>
                Gets the message key value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Timestamp">
            <summary>
                Gets the message timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.Error">
            <summary>
                Gets a rich <see cref="P:Confluent.Kafka.Message.Error"/> associated with the message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.TopicPartitionOffset">
            <summary>
                Gets the topic/partition/offset associated with this message.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Message.TopicPartition">
            <summary>
                Gets the topic/partition associated with this message.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Metadata">
            <summary>
                Kafka cluster metadata.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Metadata.#ctor(System.Collections.Generic.List{Confluent.Kafka.BrokerMetadata},System.Collections.Generic.List{Confluent.Kafka.TopicMetadata},System.Int32,System.String)">
            <summary>
                Instantiates a new Metadata class instance.
            </summary>
            <param name="brokers">
                Information about each constituent broker of the cluster.
            </param>
            <param name="topics">
                Information about requested topics in the cluster.
            </param>
            <param name="originatingBrokerId">
                The id of the broker that provided this metadata.
            </param>
            <param name="originatingBrokerName">
                The name of the broker that provided this metadata.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Metadata.Brokers">
            <summary>
                Gets information about each constituent broker of the cluster.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Metadata.Topics">
            <summary>
                Gets information about requested topics in the cluster.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Metadata.OriginatingBrokerId">
            <summary>
                Gets the id of the broker that provided this metadata.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Metadata.OriginatingBrokerName">
            <summary>
                Gets the name of the broker that provided this metadata.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Metadata.ToString">
            <summary>
                Returns a JSON representation of the Metadata object.
            </summary>
            <returns>
                A JSON representation of the Metadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Null">
            <summary>
                A type for use in conjunction with <see cref="T:Confluent.Kafka.Serialization.NullSerializer" />
                and <see cref="T:Confluent.Kafka.Serialization.NullDeserializer" /> that enables null key or 
                values to be enforced when producing or consuming messages.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.Offset">
            <summary>
                Represents a Kafka partition offset value.
            </summary>  
            <remarks>
                This structure is the same size as a long - 
                its purpose is to add some syntactical sugar 
                related to special values.
            </remarks>
        </member>
        <member name="P:Confluent.Kafka.Offset.Beginning">
            <summary>
                A special value that refers to the beginning of a partition.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Confluent.Kafka.Offset.End">
            <summary>
                A special value that refers to the end of a partition.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Confluent.Kafka.Offset.Stored">
            <summary>
                A special value thet refers to the stored offset for a partition.
            </summary>
            <returns></returns>
        </member>
        <member name="P:Confluent.Kafka.Offset.Invalid">
            <summary>
                A special value that refers to an invalid, unassigned or default partition offset.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Offset.#ctor(System.Int64)">
            <summary>
                Initializes a new instance of the Offset structure.
            </summary>
            <param name="offset">
                The offset value
            </param>
        </member>
        <member name="P:Confluent.Kafka.Offset.Value">
            <summary>
                Gets the long value corresponding to this offset.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Offset.IsSpecial">
            <summary>
                Gets whether or not this is one of the special 
                offset values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Offset.Equals(System.Object)">
            <summary>
                Tests whether this Offset value is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is an Offset and has the same value. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Equality(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Inequality(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is not equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_GreaterThan(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is greater than Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is greater than Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_LessThan(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is less than Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is less than Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_GreaterThanOrEqual(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is greater than or equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is greater than or equal to Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_LessThanOrEqual(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Tests whether Offset value a is less than or equal to Offset value b.
            </summary>
            <param name="a">
                The first Offset value to compare.
            </param>
            <param name="b">
                The second Offset value to compare.
            </param>
            <returns>
                true if Offset value a is less than or equal to Offset value b. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.GetHashCode">
            <summary>
                Returns a hash code for this Offset.
            </summary>
            <returns>
                An integer that specifies a hash value for this Offset.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Implicit(System.Int64)~Confluent.Kafka.Offset">
            <summary>
                Converts the specified long value to an Offset value.
            </summary>
            <param name="v">
                THe long value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Offset.op_Implicit(Confluent.Kafka.Offset)~System.Int64">
            <summary>
                Converts the specified Offset value to a long value.
            </summary>
            <param name="o">
                The Offset value to convert.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Offset.ToString">
            <summary>
                Returns a string representation of the Offset object.
            </summary>
            <returns>
                A string that represents the Offset object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.PartitionMetadata">
            <summary>
                Metadata pertaining to a single Kafka topic partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.PartitionMetadata.#ctor(System.Int32,System.Int32,System.Int32[],System.Int32[],Confluent.Kafka.Error)">
            <summary>
                Initializes a new PartitionMetadata instance.
            </summary>
            <param name="partitionId">
                The id of the partition this metadata relates to.
            </param>
            <param name="leader">
                The id of the broker that is the leader for the partition.
            </param>
            <param name="replicas">
                The ids of all brokers that contain replicas of the partition.
            </param>
            <param name="inSyncReplicas">
                The ids of all brokers that contain in-sync replicas of the partition.
                Note: this value is cached by the broker and is consequently not guarenteed to be up-to-date.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.PartitionMetadata.Error"/> object associated with the request for this partition metadata.
            </param>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.PartitionId">
            <summary>
                Gets ths id of the partition this metadata relates to.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.Leader">
            <summary>
                Gets the id of the broker that is the leader for the partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.Replicas">
            <summary>
                Gets the ids of all brokers that contain replicas of the partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.InSyncReplicas">
            <summary>
                Gets the ids of all brokers that contain in-sync replicas of the partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.PartitionMetadata.Error">
            <summary>
                Gets a rich <see cref="P:Confluent.Kafka.PartitionMetadata.Error"/> object associated with the request for this partition metadata.
                Note: this value is cached by the broker and is consequently not guarenteed to be up-to-date.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.PartitionMetadata.ToString">
            <summary>
                Returns a JSON representation of the PartitionMetadata object.
            </summary>
            <returns>
                A JSON representation the PartitionMetadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Producer">
            <summary>
                Implements a high-level Apache Kafka producer (without serialization).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.getKafkaTopicHandle(System.String)">
            <remarks>
                getKafkaTopicHandle() is now only required by GetMetadata() which still requires that 
                topic is specified via a handle rather than a string name (note that getKafkaTopicHandle() 
                was also formerly required by the ProduceAsync methods). Eventually we would like to 
                depreciate this method as well as the SafeTopicHandle class.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.DeliveryReportCallbackImpl(System.IntPtr,System.IntPtr,System.IntPtr)">
            <remarks>
                note: this property is set to that defined in rd_kafka_conf
                (which is never used by confluent-kafka-dotnet).
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean,System.Boolean)">
            <summary>
                Initializes a new Producer instance.
            </summary>
            <param name="config">
                librdkafka configuration parameters (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md).
                Topic configuration parameters are specified via the "default.topic.config" sub-dictionary config parameter.
            </param>
            <param name="manualPoll">
                If true, does not start a dedicated polling thread to trigger events or receive delivery reports -
                you must call the Poll method periodically instead. Typically you should set this parameter to false.
            </param>
            <param name="disableDeliveryReports">
                If true, disables delivery report notification. Note: if set to true and you use a ProduceAsync variant that returns
                a Task, the Tasks will never complete. Typically you should set this parameter to false. Set it to true for "fire and
                forget" semantics and a small boost in performance.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}})">
            <summary>
                Initializes a new Producer instance.
            </summary>
            <param name="config">
                librdkafka configuration parameters (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md).
                Topic configuration parameters are specified via the "default.topic.config" sub-dictionary config parameter.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer.Poll(System.Int32)">
            <summary>
                Poll for callback events. You will not typically need
                to call this method. Only call on producer instances 
                where background polling is not enabled.
            </summary>
            <param name="millisecondsTimeout">
                The maximum period of time to block (in milliseconds) if no
                callback events are waiting or -1 to block indefinitely. 
                You should typically use a relatively short timout period 
                because this operation cannot be cancelled.
            </param>
            <returns>
                Returns the number of events served.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.Poll(System.TimeSpan)">
            <summary>
                Poll for callback events. You will not typically need
                to call this method. Only call on producer instances 
                where background polling is not enabled.
            </summary>
            <param name="timeout">
                The maximum period of time to block if no callback events
                are waiting. You should typically use a relatively short 
                timout period because this operation cannot be cancelled.
            </param>
            <returns>
                Returns the number of events served.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.Poll">
            <summary>
                Poll for callback events. You will not typically need
                to call this method. Only call on producer
                instances where background polling is not enabled.
                Blocks until there is a callback event ready to be served.
            </summary>
            <returns>
                Returns the number of events served.
            </returns>
        </member>
        <member name="E:Confluent.Kafka.Producer.OnError">
            <summary>
                Raised on critical errors, e.g. connection failures or all 
                brokers down. Note that the client will try to automatically 
                recover from errors - these errors should be seen as 
                informational rather than catastrophic
            </summary>
            <remarks>
                Called on the Producer poll thread.
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Producer.OnStatistics">
             <summary>
                 Raised on librdkafka statistics events. JSON formatted
                 string as defined here: https://github.com/edenhill/librdkafka/wiki/Statistics
             </summary>
             <remarks>
                 You can enable statistics and set the statistics interval
                 using the statistics.interval.ms configuration parameter
                 (disabled by default).
            
                 Called on the Producer poll thread.
             </remarks>
        </member>
        <member name="E:Confluent.Kafka.Producer.OnLog">
             <summary>
                 Raised when there is information that should be logged.
             </summary>
             <remarks>
                 By default not many log messages are generated.
             
                 You can specify one or more debug contexts using the 'debug'
                 configuration property and a log level using the 'log_level'
                 configuration property to enable more verbose logging,
                 however you shouldn't typically need to do this.
            
                 Warning: Log handlers are called spontaneously from internal librdkafka 
                 threads and the application must not call any Confluent.Kafka APIs from 
                 within a log handler or perform any prolonged operations.
             </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.GetSerializingProducer``2(Confluent.Kafka.Serialization.ISerializer{``0},Confluent.Kafka.Serialization.ISerializer{``1})">
            <summary>
                Returns a serializing producer that uses this Producer to 
                produce messages. The same underlying Producer can be used
                as the basis of many serializing producers (potentially with
                different TKey and TValue types). Threadsafe.
            </summary>
            <param name="keySerializer">
                The key serializer.
            </param>
            <param name="valueSerializer">
                The value serializer.
            </param>
            <typeparam name="TKey">
                The key type.
            </typeparam>
            <typeparam name="TValue">
                The value type.
            </typeparam>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Byte[])">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean)" /> 
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32)">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean)" /> 
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32)">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean)" /> 
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
                Asynchronously send a single message to the broker.
            </summary>
            <param name="topic">
                The target topic.
            </param>
            <param name="partition">
                The target partition (if -1, this is determined by the partitioner
                configured for the topic).
            </param>
            <param name="key">
                null, or a byte array that contains the message key.
            </param>
            <param name="keyOffset">
                for non-null values, the offset into the key array of the
                sub-array to use as the message key.
                if <paramref name="key" />  is null, keyOffset must be 0.
            </param>
            <param name="keyLength">
                for non-null keys, the length of the sequence of bytes that
                constitutes the key.
                if <paramref name="key" />  is null, keyOffset must be 0.
            </param>
            <param name="val">
                null, or a byte array that contains the message value.
            </param>
            <param name="valOffset">
                for non-null values, the offset into the val array of the
                sub-array to use as the message value.
                if <paramref name="val" /> is null, valOffset must be 0.
            </param>
            <param name="valLength">
                for non-null values, the length of the sequence of bytes that
                constitutes the value.
                if <paramref name="val" /> is null, valLength must be 0.
            </param>
            <param name="blockIfQueueFull">
                Whether or not to block if the send queue is full.
                If false, a KafkaExcepion (with Error.Code == ErrorCode.Local_QueueFull) 
                will be thrown if an attempt is made to produce a message
                and the send queue is full.
            
                Warning: blockIfQueueFull is set to true, background polling is 
                disabled and Poll is not being called in another thread, this
                will block indefinitely.
            </param>
            <returns>
                A Task which will complete with the corresponding delivery report
                for this request.
            </returns>
            <remarks>
                If you require strict ordering of delivery reports to be maintained, 
                you should use a variant of ProduceAsync that takes an IDeliveryHandler
                parameter, not a variant that returns a Task&lt;Message&gt; because 
                Tasks are completed on arbitrary thread pool threads and can 
                be executed out of order.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Boolean)">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean)" />
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Byte[],Confluent.Kafka.IDeliveryHandler)">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler)" /> 
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,Confluent.Kafka.IDeliveryHandler)">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler)" />
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,Confluent.Kafka.IDeliveryHandler)">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler)" /> 
                for more information.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler)">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
            </summary>
            <remarks>
                Notification of delivery reports is via an IDeliveryHandler instance. Use IDeliveryHandler variants of 
                ProduceAsync if you require notification of delivery reports strictly in the order they were 
                acknowledged by the broker / failed (failure may be via broker or local). IDeliveryHandler.HandleDeliveryReport
                callbacks are executed on the Poll thread.
                
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean)" /> 
                for more information.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler)">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                Refer to <see cref="M:Confluent.Kafka.Producer.ProduceAsync(System.String,System.Byte[],System.Int32,System.Int32,System.Byte[],System.Int32,System.Int32,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler)" /> 
                for more information.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer.Name">
            <summary>
                Gets the name of this producer instance.
                Contains (but is not equal to) the client.id configuration parameter.
            </summary>
            <remarks>
                This name will be unique across all producer instances
                in a given application which allows log messages to be
                associated with the corresponding instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.Flush(System.Int32)">
             <summary>
                 Wait until all outstanding produce requests and delievery report
                 callbacks are completed.
             
                 [UNSTABLE-API] - the semantics and/or type of the return value is
                 subject to change.
             </summary>
             <param name="millisecondsTimeout">
                 The maximum time to block in milliseconds or -1 to block
                 indefinitely. You should typically use a relatively short timout 
                 period because this operation cannot be cancelled.
             </param>
             <returns>
                 The current librdkafka out queue length. This should be interpreted
                 as a rough indication of the number of messages waiting to be sent
                 to or acknowledged by the broker. If zero, there are no outstanding
                 messages or callbacks. Specifically, the value is equal to the sum
                 of the number of produced messages for which a delivery report has
                 not yet been handled and a number which is less than or equal to the
                 number of pending delivery report callback events (as determined by
                 an internal librdkafka implementation detail).
             </returns>
             <remarks>
                 This method should typically be called prior to destroying a producer
                 instance to make sure all queued and in-flight produce requests are
                 completed before terminating. The wait time is bounded by the
                 millisecondsTimeout parameter.
            
                 A related default.topic.config configuration parameter is message.timeout.ms
                 which determines the maximum length of time librdkafka attempts to deliver
                 the message before giving up and so also affects the maximum time a call
                 to Flush may block.
             </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.Flush(System.TimeSpan)">
            <summary>
                Wait until all outstanding produce requests and delievery report
                callbacks are completed. Refer to <see cref="M:Confluent.Kafka.Producer.Flush(System.Int32)" /> for
                more information.
            
                [UNSTABLE-API] - the semantics and/or type of the return value is
                subject to change.
            </summary>
            <param name="timeout">
                The maximum length of time to block. You should typically use a
                relatively short timout period because this operation cannot be 
                cancelled.
            </param>
            <returns>
                The current librdkafka out queue length. Refer to <see cref="M:Confluent.Kafka.Producer.Flush(System.Int32)" />
                for more information.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.Flush">
             <summary>
                 Equivalent to <see cref="M:Confluent.Kafka.Producer.Flush(System.Int32)" /> with infinite timeout.
            
                 [UNSTABLE-API] - the semantics and/or type of the return value is
                 subject to change.
             </summary>
             <returns>
                 Refer to <see cref="M:Confluent.Kafka.Producer.Flush(System.Int32)" />.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.Dispose">
            <summary>
                Releases all resources used by this Producer.
            </summary>
            <remarks>
                You will often want to call <see cref="M:Confluent.Kafka.Producer.Flush" />
                before disposing a Producer instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer.ListGroups(System.TimeSpan)">
             <summary>
                 Get information pertaining to all groups in the Kafka cluster (blocking)
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Producer.ListGroup(System.String,System.TimeSpan)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.ListGroup(System.String)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.TimeSpan)">
             <summary>
                 Query the cluster for metadata (blocking).
            
                 - allTopics = true - request all topics from cluster
                 - allTopics = false, topic = null - request only locally known topics.
                 - allTopics = false, topic = valid - request specific topic
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String)">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.TimeSpan)" />
            
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.GetMetadata">
            <summary>
                Refer to <see cref="M:Confluent.Kafka.Producer.GetMetadata(System.Boolean,System.String,System.TimeSpan)" />
            
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer.AddBrokers(System.String)">
             <summary>
                 Adds one or more brokers to the Producer's list of initial
                 bootstrap brokers. 
            
                 Note: Additional brokers are discovered automatically as 
                 soon as the Producer connects to any broker by querying the 
                 broker metadata. Calling this method is only required in 
                 some scenarios where the address of all brokers in the 
                 cluster changes.
             </summary>
             <param name="brokers">
                 Coma-separated list of brokers in the same format as 
                 the bootstrap.server configuration parameter.
             </param>
             <remarks>
                 There is currently no API to remove existing configured, 
                 added or learnt brokers.
             </remarks>
             <returns>
                 The number of brokers added. This value includes brokers
                 that may have been specified a second time.
             </returns>
        </member>
        <member name="T:Confluent.Kafka.Producer`2">
            <summary>
                Implements a high-level Apache Kafka producer with key
                and value serialization.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},Confluent.Kafka.Serialization.ISerializer{`0},Confluent.Kafka.Serialization.ISerializer{`1},System.Boolean,System.Boolean)">
            <summary>
                Creates a new Producer instance.
            </summary>
            <param name="config">
                librdkafka configuration parameters (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md).
                Topic configuration parameters are specified via the "default.topic.config" sub-dictionary config parameter.
            </param>
            <param name="keySerializer">
                An ISerializer implementation instance that will be used to serialize keys.
            </param>
            <param name="valueSerializer">
                An ISerializer implementation instance that will be used to serialize values.
            </param>
            <param name="manualPoll">
                If true, does not start a dedicated polling thread to trigger events or receive delivery reports -
                you must call the Poll method periodically instead. Typically you should set this parameter to false.
            </param>
            <param name="disableDeliveryReports">
                If true, disables delivery report notification. Note: if set to true and you use a ProduceAsync variant that returns
                a Task, the Tasks will never complete. Typically you should set this parameter to false. Set it to true for "fire and
                forget" semantics and a small boost in performance.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.#ctor(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},Confluent.Kafka.Serialization.ISerializer{`0},Confluent.Kafka.Serialization.ISerializer{`1})">
            <summary>
                Initializes a new Producer instance.
            </summary>
            <param name="config">
                librdkafka configuration parameters (refer to https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md).
                Topic configuration parameters are specified via the "default.topic.config" sub-dictionary config parameter.
            </param>
            <param name="keySerializer">
                An ISerializer implementation instance that will be used to serialize keys.
            </param>
            <param name="valueSerializer">
                An ISerializer implementation instance that will be used to serialize values.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Producer`2.KeySerializer">
            <summary>
                Gets the ISerializer implementation instance used to serialize keys.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer`2.ValueSerializer">
            <summary>
                Gets the ISerializer implementation instance used to serialize values.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Producer`2.Name">
            <summary>
                Gets the name of this producer instance.
                Contains (but is not equal to) the client.id configuration parameter.
            </summary>
            <remarks>
                This name will be unique across all producer instances
                in a given application which allows log messages to be
                associated with the corresponding instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1)">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)" /> for more information.
            </summary>
            <remarks>
                The partition the message is produced to is determined using the configured partitioner.
                
                Blocks if the send queue is full. Warning: if background polling is disabled and Poll is
                not being called in another thread, this will block indefinitely.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)">
            <summary>
                Asynchronously send a single message to the broker.
            </summary>
            <param name="topic">
                The target topic.
            </param>
            <param name="partition">
                The target partition (if -1, this is determined by the partitioner
                configured for the topic).
            </param>
            <param name="key">
                the message key (possibly null if allowed by the key serializer).
            </param>
            <param name="val">
                the message value (possibly null if allowed by the value serializer).
            </param>
            <param name="blockIfQueueFull">
                Whether or not to block if the send queue is full.
                If false, a KafkaExcepion (with Error.Code == ErrorCode.Local_QueueFull) 
                will be thrown if an attempt is made to produce a message
                and the send queue is full.
                 
                Warning: blockIfQueueFull is set to true, background polling is 
                disabled and Poll is not being called in another thread, 
                this will block indefinitely.
            </param>
            <returns>
                A Task which will complete with the corresponding delivery report
                for this request.
            </returns>
            <remarks>
                If you require strict ordering of delivery reports to be maintained, 
                you should use a variant of ProduceAsync that takes an IDeliveryHandler
                parameter, not a variant that returns a Task&lt;Message&gt; because 
                Tasks are completed on arbitrary thread pool threads and can 
                be executed out of order.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32)">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)" /> for more information.
            </summary>
            <remarks>
                Blocks if the send queue is full. Warning: if background polling is disabled and Poll is
                not being called in another thread, this will block indefinitely.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Boolean)">
            <summary>
                Asynchronously send a single message to the broker.
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)" /> for more information.
            </summary>
            <remarks>
                The partition the message is produced to is determined using the configured partitioner.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                See <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})"/> for more information.
            </summary>
            <remarks>
                The partition the message is produced to is determined using the configured partitioner.
                
                Blocks if the send queue is full. Warning: if background polling is disabled and Poll is
                not being called in another thread, this will block indefinitely.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
            </summary>
            <remarks>
                Notification of delivery reports is via an IDeliveryHandler instance. Use IDeliveryHandler variants of 
                ProduceAsync if you require notification of delivery reports strictly in the order they were 
                acknowledged by the broker / failed (failure may be via broker or local). IDeliveryHandler.HandleDeliveryReport
                callbacks are executed on the Poll thread.
                
                Refer to <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean)" />
                for more information.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                See <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})"/> for more information.
            </summary>
            <remarks>
                Blocks if the send queue is full. Warning: if background polling is disabled and Poll is
                not being called in another thread, this will block indefinitely.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})">
            <summary>
                Asynchronously send a single message to the broker (order of delivery reports strictly guarenteed).
                See <see cref="M:Confluent.Kafka.Producer`2.ProduceAsync(System.String,`0,`1,System.Int32,System.Boolean,Confluent.Kafka.IDeliveryHandler{`0,`1})"/> for more information.
            </summary>
            <remarks>
                The partition the message is produced to is determined using the configured partitioner.
            </remarks>
        </member>
        <member name="E:Confluent.Kafka.Producer`2.OnLog">
             <summary>
                 Raised when there is information that should be logged.
             </summary>
             <remarks>
                 Note: By default not many log messages are generated.
             
                 You can specify one or more debug contexts using the 'debug'
                 configuration property and a log level using the 'log_level'
                 configuration property to enable more verbose logging,
                 however you shouldn't typically need to do this.
            
                 Warning: Log handlers are called spontaneously from internal librdkafka 
                 threads and the application must not call any Confluent.Kafka APIs from 
                 within a log handler or perform any prolonged operations.
             </remarks>
        </member>
        <member name="E:Confluent.Kafka.Producer`2.OnStatistics">
             <summary>
                 Raised on librdkafka statistics events. JSON formatted
                 string as defined here: https://github.com/edenhill/librdkafka/wiki/Statistics
             </summary>
             <remarks>
                 You can enable statistics and set the statistics interval
                 using the statistics.interval.ms configuration parameter
                 (disabled by default).
            
                 Called on the Producer poll thread.
             </remarks>
        </member>
        <member name="E:Confluent.Kafka.Producer`2.OnError">
            <summary>
                Raised on critical errors, e.g. connection failures or all 
                brokers down. Note that the client will try to automatically 
                recover from errors - these errors should be seen as 
                informational rather than catastrophic
            </summary>
            <remarks>
                Called on the Producer poll thread.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Flush(System.Int32)">
             <summary>
                 Wait until all outstanding produce requests and delievery report
                 callbacks are completed.
             
                 [UNSTABLE-API] - the semantics and/or type of the return value is
                 subject to change.
             </summary>
             <param name="millisecondsTimeout">
                 The maximum time to block in milliseconds, or -1 to block
                 indefinitely. You should typically use a relatively short timout 
                 period because this operation cannot be cancelled.
             </param>
             <returns>
                 The current librdkafka out queue length. This should be interpreted
                 as a rough indication of the number of messages waiting to be sent
                 to or acknowledged by the broker. If zero, there are no outstanding
                 messages or callbacks. Specifically, the value is equal to the sum
                 of the number of produced messages for which a delivery report has
                 not yet been handled and a number which is less than or equal to the
                 number of pending delivery report callback events (as determined by
                 an internal librdkafka implementation detail).
             </returns>
             <remarks>
                 This method should typically be called prior to destroying a producer
                 instance to make sure all queued and in-flight produce requests are
                 completed before terminating. The wait time is bounded by the
                 millisecondsTimeout parameter.
            
                 A related default.topic.config configuration parameter is message.timeout.ms
                 which determines the maximum length of time librdkafka attempts to deliver
                 the message before giving up and so also affects the maximum time a call
                 to Flush may block.
             </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Flush(System.TimeSpan)">
            <summary>
                Wait until all outstanding produce requests and delievery report
                callbacks are completed. Refer to <see cref="M:Confluent.Kafka.Producer`2.Flush(System.Int32)" /> for
                more information.
            
                [UNSTABLE-API] - the semantics and/or type of the return value is
                subject to change.
            </summary>
            <param name="timeout">
                The maximum length of time to block. You should typically use a
                relatively short timout period because this operation cannot be 
                cancelled.
            </param>
            <returns>
                The current librdkafka out queue length. Refer to <see cref="M:Confluent.Kafka.Producer`2.Flush(System.Int32)" />
                for more information.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.Dispose">
            <summary>
                Releases all resources used by this Producer.
            </summary>
            <remarks>
                You will often want to call <see cref="M:Confluent.Kafka.Producer`2.Flush(System.Int32)" />
                before disposing a Producer instance.
            </remarks>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ListGroups(System.TimeSpan)">
             <summary>
                 Get information pertaining to all groups in the Kafka cluster (blocking)
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ListGroup(System.String,System.TimeSpan)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocks)
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.ListGroup(System.String)">
             <summary>
                 Get information pertaining to a particular group in the
                 Kafka cluster (blocks, potentially indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="group">
                 The group of interest.
             </param>
             <returns>
                 Returns information pertaining to the specified group
                 or null if this group does not exist.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition,System.TimeSpan)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocking).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <param name="timeout">
                 The maximum period of time the call may block.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.QueryWatermarkOffsets(Confluent.Kafka.TopicPartition)">
             <summary>
                 Query the Kafka cluster for low (oldest/beginning) and high (newest/end)
                 offsets for the specified topic/partition (blocks, potentialy indefinitely).
            
                 [UNSTABLE-API] - The API associated with this functionality is subject to change.
             </summary>
             <param name="topicPartition">
                 The topic/partition of interest.
             </param>
             <returns>
                 The requested WatermarkOffsets.
             </returns>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.GetMetadata(System.Boolean,System.String,System.TimeSpan)">
            <summary>
                Refer to Producer.GetMetadata(bool, string, TimeSpan) for more information.
                
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.GetMetadata(System.Boolean,System.String)">
            <summary>
                Refer to Producer.GetMetadata(bool, string) for more information
                
                [UNSTABLE-API] - The API associated with this functionality is subject to change.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Producer`2.AddBrokers(System.String)">
             <summary>
                 Adds one or more brokers to the Producer's list of initial
                 bootstrap brokers. 
            
                 Note: Additional brokers are discovered automatically as 
                 soon as the Producer connects to any broker by querying the 
                 broker metadata. Calling this method is only required in 
                 some scenarios where the address of all brokers in the 
                 cluster changes.
             </summary>
             <param name="brokers">
                 Coma-separated list of brokers in the same format as 
                 the bootstrap.server configuration parameter.
             </param>
             <remarks>
                 There is currently no API to remove existing configured, 
                 added or learnt brokers.
             </remarks>
             <returns>
                 The number of brokers added. This value includes brokers
                 that may have been specified a second time.
             </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.ByteArrayDeserializer">
            <summary>
                A deserializer for System.Byte[] values. This deserializer simply passes through the provided System.Byte[] value.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.ByteArrayDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserializes a System.Byte[] value (or null) from a byte array.
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="data">
                A byte array containing the serialized System.Byte[] value (or null).
            </param>
            <returns>
                The deserialized System.Byte[] value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.ByteArrayDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.ByteArraySerializer">
            <summary>
                System.Byte[] serializer. This serializer simply passes through the provided System.Byte[] value.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.ByteArraySerializer.Serialize(System.String,System.Byte[])">
            <summary>
                Serializes the specified System.Byte[] value (or null) to a byte array. Byte order is original order. 
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <param name="data">
                The System.Byte[] value to serialize (or null).
            </param>
            <returns>
                The System.Byte[] value <paramref name="data" /> encoded as a byte array. 
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.ByteArraySerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.DoubleDeserializer">
            <summary>
                A deserializer for big endian encoded (network byte ordered) System.Double values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.DoubleDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserializes a big endian encoded (network byte ordered) System.Double value from a byte array.
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="data">
                A byte array containing the serialized System.Double value (big endian encoding).
            </param>
            <returns>
                The deserialized System.Double value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.DoubleDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.DoubleSerializer">
            <summary>
                System.Double serializer. Byte order of serialized data is big endian (network byte order).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.DoubleSerializer.Serialize(System.String,System.Double)">
            <summary>
                Serializes the specified System.Double value to a byte array of length 8. Byte order is big endian (network byte order).
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <param name="data">
                The System.Double value to serialize.
            </param>
            <returns>
                The System.Double value <paramref name="data" /> encoded as a byte array of length 4 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.DoubleSerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.MessageExtensions">
            <summary>
                Provides extension methods on the <see cref="T:Confluent.Kafka.Message" /> class.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.MessageExtensions.Deserialize``2(Confluent.Kafka.Message,Confluent.Kafka.Serialization.IDeserializer{``0},Confluent.Kafka.Serialization.IDeserializer{``1})">
            <summary>
                Deserializes a Message instance's key and value and returns 
                the corresponding typed Message instance.
            </summary>
            <param name="message">
                The message instance for which to deserialize the key and value.
            </param>
            <param name="keyDeserializer">
                The deserializer to use to deserialize the key.
            </param>
            <param name="valueDeserializer">
                The deserializer to use to deserialize the value.
            </param>
            <returns>
                A typed message instance corresponding to <paramref name="message" />.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.FloatDeserializer">
            <summary>
                A deserializer for big endian encoded (network byte ordered) System.Single values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.FloatDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserializes a big endian encoded (network byte ordered) System.Single value from a byte array.
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <param name="data">
                A byte array containing the serialized System.Single value (big endian encoding).
            </param>
            <returns>
                The deserialized System.Single value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.FloatDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.FloatSerializer">
            <summary>
                System.Single serializer. Byte order of serialized data is big endian (network byte order).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.FloatSerializer.Serialize(System.String,System.Single)">
            <summary>
                Serializes the specified System.Single value to a byte array of length 4. Byte order is big endian (network byte order).
            </summary>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <param name="data">
                The System.Single value to serialize.
            </param>
            <returns>
                The System.Single value <paramref name="data" /> encoded as a byte array of length 4 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.FloatSerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.IDeserializer`1">
            <summary>
                Implement this interface to define a deserializer 
                for a particular type T.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IDeserializer`1.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserialize a byte array to an instance of
                type T.
            </summary>
            <param name="topic">
                The topic associated wih the data.
            </param>
            <param name="data">
                The serialized representation of an instance
                of type T to deserialize.
            </param>
            <returns>
                The deserialized value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IDeserializer`1.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.IgnoreDeserializer">
            <summary>
                A 'deserializer' that returns null regardless of the input data.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IgnoreDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                'Deserializes' any data to a null value.
            </summary>
            <param name="data">
                The data to deserialize.
            </param>        
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <returns>
                null
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IgnoreDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.IntDeserializer">
            <summary>
                A deserializer for big endian encoded (network byte ordered) <see cref="T:System.Int32"/> values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IntDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserializes a big endian encoded (network byte ordered) <see cref="T:System.Int32"/> value from a byte array.
            </summary>
            <param name="data">
                A byte array containing the serialized <see cref="T:System.Int32"/> value (big endian encoding).
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <returns>
                The deserialized <see cref="T:System.Int32"/> value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IntDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.IntSerializer">
            <summary>
                A serializer for <see cref="T:System.Int32"/> values. The byte order of serialized data is big endian (network byte order).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IntSerializer.Serialize(System.String,System.Int32)">
            <summary>
                Serializes the specified <see cref="T:System.Int32"/> value to a byte array of length 4. Byte order is big endian (network byte order).
            </summary>
            <param name="data">
                The <see cref="T:System.Int32"/> value to serialize.
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <returns>
                The <see cref="T:System.Int32"/> value <paramref name="data" /> encoded as a byte array of length 8 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.IntSerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.ISerializer`1">
            <summary>
                Implement this interface to define a serializer 
                for a particular type T.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.ISerializer`1.Serialize(System.String,`0)">
            <summary>
                Serialize an instance of type T to a byte array.
            </summary>
            <param name="topic">
                The topic associated wih the data.
            </param>
            <param name="data">
                The object to serialize.
            </param>
            <returns>
                <paramref name="data" /> serialized as a byte array.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.ISerializer`1.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.LongDeserializer">
            <summary>
                A deserializer for big endian encoded (network byte ordered) <see cref="T:System.Int64"/> values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.LongDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserializes a big endian encoded (network byte ordered) <see cref="T:System.Int64"/> value from a byte array.
            </summary>
            <param name="data">
                A byte array containing the serialized <see cref="T:System.Int64"/> value (big endian encoding)
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <returns>
                The deserialized <see cref="T:System.Int64"/> value.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.LongDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.LongSerializer">
            <summary>
                A serializer for <see cref="T:System.Int64"/> values. The byte order of serialized data is big endian (network byte order).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.LongSerializer.Serialize(System.String,System.Int64)">
            <summary>
                Serializes the specified <see cref="T:System.Int64"/> value to a byte array of length 8. Byte order is big endian (network byte order).
            </summary>
            <param name="data">
                The <see cref="T:System.Int64"/> value to serialize.
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <returns>
                The <see cref="T:System.Int64"/> value <paramref name="data" /> encoded as a byte array of length 8 (network byte order).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.LongSerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.NullDeserializer">
            <summary>
                A dummy deserializer for use with values that must be null.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.NullDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                'Deserializes' a null value to a null value.
            </summary>
            <param name="data">
                The data to deserialize (must be null).
            </param>        
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <returns>
                null
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.NullDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.NullSerializer">
            <summary>
                A dummy serializer for use with values that must be null (the <see cref="T:Confluent.Kafka.Null"/> class cannot be instantiated).
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.NullSerializer.Serialize(System.String,Confluent.Kafka.Null)">
            <param name="data">
                Can only be null (the <see cref="T:Confluent.Kafka.Null"/> class cannot be instantiated).
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <returns>
                null
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.NullSerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.StringDeserializer">
            <summary>
                A deserializer for string values.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serialization.StringDeserializer.KeyEncodingConfigParam">
            <summary>
                Name of the configuration parameter used to specify the encoding when deserializing keys.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serialization.StringDeserializer.ValueEncodingConfigParam">
            <summary>
                Name of the configuration parameter used to specify the encoding when deserializing values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringDeserializer.#ctor(System.Text.Encoding)">
            <summary>
                Initializes a new StringDeserializer class instance.
            </summary>
            <param name="encoding">
                The encoding to use when deserializing.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringDeserializer.#ctor">
            <summary>
                Initializes a new StringDeserializer class instance.
                The encoding to use must be provided via a <see cref="T:Confluent.Kafka.Consumer" /> 
                configuration property. When used to deserialize keys, the 
                relevant property is 'dotnet.string.deserializer.encoding.key'.
                When used to deserialize values, the relevant property is
                'dotnet.string.deserializer.encoding.value'. For available encodings, 
                refer to:
                https://msdn.microsoft.com/en-us/library/system.text.encoding(v=vs.110).aspx
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringDeserializer.Deserialize(System.String,System.Byte[])">
            <summary>
                Deserializes a string value from a byte array.
            </summary>
            <param name="data">
                The data to deserialize.
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this deserializer).
            </param>
            <returns>
                <paramref name="data" /> deserialized to a string (or null if data is null).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringDeserializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the deserializer using relevant configuration parameter(s) in <paramref name="config" /> (if present).
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this deserializer.
    </param><param name="isKey">
        true: if this deserializer instance is used to serialize keys,
        false: if this deserializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this deserializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Serialization.StringSerializer">
            <summary>
                A serializer for string values.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serialization.StringSerializer.KeyEncodingConfigParam">
            <summary>
                Name of the configuration parameter used to specify the encoding when serializing keys.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Serialization.StringSerializer.ValueEncodingConfigParam">
            <summary>
                Name of the configuration parameter used to specify the encoding when serializing values.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringSerializer.#ctor(System.Text.Encoding)">
            <summary>
                Initializes a new StringSerializer class instance.
            </summary>
            <param name="encoding">
                The encoding to use when serializing. 
            </param>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringSerializer.#ctor">
            <summary>
                Initializes a new StringSerializer class instance.
                The encoding to use must be provided via a <see cref="T:Confluent.Kafka.Producer" /> 
                configuration property. When used to serialize keys, the 
                relevant property is 'dotnet.string.serializer.encoding.key'.
                When used to serialize values, the relevant property is
                'dotnet.string.serializer.encoding.value'. For available encodings, 
                refer to:
                https://msdn.microsoft.com/en-us/library/system.text.encoding(v=vs.110).aspx
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringSerializer.Serialize(System.String,System.String)">
            <summary>
                Encodes a string value in a byte array.
            </summary>
            <param name="data">
                The string value to serialize.
            </param>
            <param name="topic">
                The topic associated with the data (ignored by this serializer).
            </param>
            <returns>
                <paramref name="data" /> encoded in a byte array (or null if <paramref name="data" /> is null).
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Serialization.StringSerializer.Configure(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,System.Object}},System.Boolean)">
            <summary>
        Configure the serializer using relevant configuration parameter(s) in <paramref name="config" /> (if present)
    </summary><param name="config">
        A collection containing configuration parameter(s) relevant to this serializer.
    </param><param name="isKey">
        true: if this serializer instance is used to serialize keys,
        false: if this serializer instance is used to serialize values.
    </param><returns>
        A configuration collection with configuration parameter(s) relevant to this serializer removed.
    </returns>
        </member>
        <member name="T:Confluent.Kafka.Timestamp">
            <summary>
                Encapsulates a Kafka timestamp and its type.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.Timestamp.UnixTimeEpoch">
            <summary>
                Unix epoch as a UTC DateTime. Unix time is defined as 
                the number of seconds past this UTC time, excluding 
                leap seconds.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.#ctor(System.Int64,Confluent.Kafka.TimestampType)">
            <summary>
                Initializes a new instance of the Timestamp structure.
            </summary>
            <param name="unixTimestampMs">
                The unix millisecond timestamp.
            </param>
            <param name="type">
                The type of the timestamp.
            </param>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.#ctor(System.DateTime,Confluent.Kafka.TimestampType)">
            <summary>
                Initializes a new instance of the Timestamp structure.
                Note: <paramref name="dateTime"/> is first converted to UTC 
                if it is not already.
            </summary>
            <param name="dateTime">
                The DateTime value to create Timestamp from.
            </param>
            <param name="type">
                The type of the timestamp.
            </param>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.Type">
            <summary>
                Gets the timestamp type.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.UnixTimestampMs">
            <summary>
                Get the Unix millisecond timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.Timestamp.UtcDateTime">
            <summary>
                Gets the UTC DateTime corresponding to the <see cref="P:Confluent.Kafka.Timestamp.UnixTimestampMs"/>.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.Equals(System.Object)">
            <summary>
                Determines whether two Timestamps have the same value
            </summary>
            <param name="obj">
                Determines whether this instance and a specified object, 
                which must also be a Timestamp object, have the same value.
            </param>
            <returns>
                true if obj is a Timestamp and its value is the same as 
                this instance; otherwise, false. If obj is null, the method 
                returns false.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.GetHashCode">
            <summary>
                Returns the hashcode for this Timestamp.
            </summary>
            <returns>
                A 32-bit signed integer hash code.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.op_Equality(Confluent.Kafka.Timestamp,Confluent.Kafka.Timestamp)">
            <summary>
                Determines whether two specified Timestamps have the same value.
            </summary>
            <param name="a">
                The first Timestamp to compare.
            </param>
            <param name="b">
                The second Timestamp to compare
            </param>
            <returns>
                true if the value of a is the same as the value of b; otherwise, false.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.op_Inequality(Confluent.Kafka.Timestamp,Confluent.Kafka.Timestamp)">
            <summary>
                Determines whether two specified Timestamps have different values.
            </summary>
            <param name="a">
                The first Timestamp to compare.
            </param>
            <param name="b">
                The second Timestamp to compare
            </param>
            <returns>
                true if the value of a is different from the value of b; otherwise, false.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.DateTimeToUnixTimestampMs(System.DateTime)">
            <summary>
                Convert a DateTime instance to a milliseconds unix timestamp.
                Note: <paramref name="dateTime"/> is first converted to UTC 
                if it is not already.
            </summary>
            <param name="dateTime">
                The DateTime value to convert.
            </param>
            <returns>
                The milliseconds unix timestamp corresponding to <paramref name="dateTime"/>
                rounded down to the previous millisecond.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.Timestamp.UnixTimestampMsToDateTime(System.Int64)">
            <summary>
                Convert a milliseconds unix timestamp to a DateTime value.
            </summary>
            <param name="unixMillisecondsTimestamp">
                The milliseconds unix timestamp to convert.
            </param>
            <returns>
                The DateTime value associated with <paramref name="unixMillisecondsTimestamp"/> with Utc Kind.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TimestampType">
            <summary>
                Enumerates the different meanings of a message timestamp value.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.TimestampType.NotAvailable">
            <summary>
                Timestamp type is unknown.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.TimestampType.CreateTime">
            <summary>
                Timestamp relates to message creation time as set by a Kafka client.
            </summary>
        </member>
        <member name="F:Confluent.Kafka.TimestampType.LogAppendTime">
            <summary>
                Timestamp relates to the time a message was appended to a Kafka log.
            </summary>
        </member>
        <member name="T:Confluent.Kafka.TopicMetadata">
            <summary>
                Metadata pertaining to a single Kafka topic.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicMetadata.#ctor(System.String,System.Collections.Generic.List{Confluent.Kafka.PartitionMetadata},Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicMetadata class instance.
            </summary>
            <param name="topic">
                The topic name.
            </param>
            <param name="partitions">
                Metadata for each of the topic's partitions.
            </param>
            <param name="error">
                A rich <see cref="P:Confluent.Kafka.TopicMetadata.Error"/> object associated with the request for this topic metadata.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicMetadata.Topic">
            <summary>
                Gets the topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicMetadata.Partitions">
            <summary>
                Gets metadata for each of the topics partitions.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicMetadata.Error">
            <summary>
                A rich <see cref="P:Confluent.Kafka.TopicMetadata.Error"/> object associated with the request for this topic metadata.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicMetadata.ToString">
            <summary>
                Returns a JSON representation of the TopicMetadata object.
            </summary>
            <returns>
                A JSON representation the TopicMetadata object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartition">
            <summary>
                Represents a Kafka (topic, partition) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.#ctor(System.String,System.Int32)">
            <summary>
                Initializes a new TopicPartition instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartition.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartition.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartition instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartition and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartition.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartition.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.op_Equality(Confluent.Kafka.TopicPartition,Confluent.Kafka.TopicPartition)">
            <summary>
                Tests whether TopicPartition instance a is equal to TopicPartition instance b.
            </summary>
            <param name="a">
                The first TopicPartition instance to compare.
            </param>
            <param name="b">
                The second TopicPartition instance to compare.
            </param>
            <returns>
                true if TopicPartition instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.op_Inequality(Confluent.Kafka.TopicPartition,Confluent.Kafka.TopicPartition)">
            <summary>
                Tests whether TopicPartition instance a is not equal to TopicPartition instance b.
            </summary>
            <param name="a">
                The first TopicPartition instance to compare.
            </param>
            <param name="b">
                The second TopicPartition instance to compare.
            </param>
            <returns>
                true if TopicPartition instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartition.ToString">
            <summary>
                Returns a string representation of the TopicPartition object.
            </summary>
            <returns>
                A string that represents the TopicPartition object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionError">
            <summary>
                Represents a Kafka (topic, partition, error) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionError instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition values.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.#ctor(System.String,System.Int32,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionError instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition value.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.Error">
            <summary>
                Gets the Kafka error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionError.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionError instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionError instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionError and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionError.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionError.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.op_Equality(Confluent.Kafka.TopicPartitionError,Confluent.Kafka.TopicPartitionError)">
            <summary>
                Tests whether TopicPartitionError instance a is equal to TopicPartitionError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionError instance to compare.
            </param>
            <returns>
                true if TopicPartitionError instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.op_Inequality(Confluent.Kafka.TopicPartitionError,Confluent.Kafka.TopicPartitionError)">
            <summary>
                Tests whether TopicPartitionError instance a is not equal to TopicPartitionError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionError instance to compare.
            </param>
            <returns>
                true if TopicPartitionError instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionError.ToString">
            <summary>
                Returns a string representation of the TopicPartitionError object.
            </summary>
            <returns>
                A string representation of the TopicPartitionError object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionOffset">
            <summary>
                Represents a Kafka (topic, partition, offset) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Offset)">
            <summary>
                Initializes a new TopicPartitionOffset instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.#ctor(System.String,System.Int32,Confluent.Kafka.Offset)">
            <summary>
                Initializes a new TopicPartitionOffset instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.Offset">
            <summary>
                Gets the Kafka partition offset value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffset.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionOffset instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionOffset instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionOffset and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionOffset.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionOffset.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.op_Equality(Confluent.Kafka.TopicPartitionOffset,Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Tests whether TopicPartitionOffset instance a is equal to TopicPartitionOffset instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffset instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffset instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffset instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.op_Inequality(Confluent.Kafka.TopicPartitionOffset,Confluent.Kafka.TopicPartitionOffset)">
            <summary>
                Tests whether TopicPartitionOffset instance a is not equal to TopicPartitionOffset instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffset instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffset instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffset instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffset.ToString">
            <summary>
                Returns a string representation of the TopicPartitionOffset object.
            </summary>
            <returns>
                A string that represents the TopicPartitionOffset object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionOffsetError">
            <summary>
                Represents a Kafka (topic, partition, offset, error) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Offset,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionOffsetError instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition values.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.#ctor(Confluent.Kafka.TopicPartitionOffset,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionOffsetError instance.
            </summary>
            <param name="tpo">
                Kafka topic name, partition and offset values.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.#ctor(System.String,System.Int32,Confluent.Kafka.Offset,Confluent.Kafka.Error)">
            <summary>
                Initializes a new TopicPartitionOffsetError instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition value.
            </param>
            <param name="offset">
                A Kafka offset value.
            </param>
            <param name="error">
                A Kafka error.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Offset">
            <summary>
                Gets the Kafka partition offset value.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.Error">
            <summary>
                Gets the Kafka error.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionOffsetError instance.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionOffsetError.TopicPartitionOffset">
            <summary>
                Gets the TopicPartitionOffset component of this TopicPartitionOffsetError instance.
            </summary>>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionOffsetError instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionOffsetError and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionOffsetError.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionOffsetError.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.op_Equality(Confluent.Kafka.TopicPartitionOffsetError,Confluent.Kafka.TopicPartitionOffsetError)">
            <summary>
                Tests whether TopicPartitionOffsetError instance a is equal to TopicPartitionOffsetError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffsetError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffsetError instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffsetError instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.op_Inequality(Confluent.Kafka.TopicPartitionOffsetError,Confluent.Kafka.TopicPartitionOffsetError)">
            <summary>
                Tests whether TopicPartitionOffsetError instance a is not equal to TopicPartitionOffsetError instance b.
            </summary>
            <param name="a">
                The first TopicPartitionOffsetError instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionOffsetError instance to compare.
            </param>
            <returns>
                true if TopicPartitionOffsetError instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.op_Explicit(Confluent.Kafka.TopicPartitionOffsetError)~Confluent.Kafka.TopicPartitionOffset">
            <summary>
                Converts TopicPartitionOffsetError instance to TopicPartitionOffset instance.
                NOTE: Throws KafkaException if Error.Code != ErrorCode.NoError 
            </summary>
            <param name="tpoe">
                The TopicPartitionOffsetError instance to convert.
            </param>
            <returns>
                TopicPartitionOffset instance converted from TopicPartitionOffsetError instance
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionOffsetError.ToString">
            <summary>
                Returns a string representation of the TopicPartitionOffsetError object.
            </summary>
            <returns>
                A string representation of the TopicPartitionOffsetError object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.TopicPartitionTimestamp">
            <summary>
                Represents a Kafka (topic, partition, timestamp) tuple.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.#ctor(Confluent.Kafka.TopicPartition,Confluent.Kafka.Timestamp)">
            <summary>
                Initializes a new TopicPartitionTimestamp instance.
            </summary>
            <param name="tp">
                Kafka topic name and partition.
            </param>
            <param name="timestamp">
                A Kafka timestamp value.
            </param>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.#ctor(System.String,System.Int32,Confluent.Kafka.Timestamp)">
            <summary>
                Initializes a new TopicPartitionTimestamp instance.
            </summary>
            <param name="topic">
                A Kafka topic name.
            </param>
            <param name="partition">
                A Kafka partition.
            </param>
            <param name="timestamp">
                A Kafka timestamp value.
            </param>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.Topic">
            <summary>
                Gets the Kafka topic name.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.Partition">
            <summary>
                Gets the Kafka partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.Timestamp">
            <summary>
                Gets the Kafka timestamp.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.TopicPartitionTimestamp.TopicPartition">
            <summary>
                Gets the TopicPartition component of this TopicPartitionTimestamp instance.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.Equals(System.Object)">
            <summary>
                Tests whether this TopicPartitionTimestamp instance is equal to the specified object.
            </summary>
            <param name="obj">
                The object to test.
            </param>
            <returns>
                true if obj is a TopicPartitionTimestamp and all properties are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.GetHashCode">
            <summary>
                Returns a hash code for this TopicPartitionTimestamp.
            </summary>
            <returns>
                An integer that specifies a hash value for this TopicPartitionTimestamp.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.op_Equality(Confluent.Kafka.TopicPartitionTimestamp,Confluent.Kafka.TopicPartitionTimestamp)">
            <summary>
                Tests whether TopicPartitionTimestamp instance a is equal to TopicPartitionTimestamp instance b.
            </summary>
            <param name="a">
                The first TopicPartitionTimestamp instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionTimestamp instance to compare.
            </param>
            <returns>
                true if TopicPartitionTimestamp instances a and b are equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.op_Inequality(Confluent.Kafka.TopicPartitionTimestamp,Confluent.Kafka.TopicPartitionTimestamp)">
            <summary>
                Tests whether TopicPartitionTimestamp instance a is not equal to TopicPartitionTimestamp instance b.
            </summary>
            <param name="a">
                The first TopicPartitionTimestamp instance to compare.
            </param>
            <param name="b">
                The second TopicPartitionTimestamp instance to compare.
            </param>
            <returns>
                true if TopicPartitionTimestamp instances a and b are not equal. false otherwise.
            </returns>
        </member>
        <member name="M:Confluent.Kafka.TopicPartitionTimestamp.ToString">
            <summary>
                Returns a string representation of the TopicPartitionTimestamp object.
            </summary>
            <returns>
                A string that represents the TopicPartitionTimestamp object.
            </returns>
        </member>
        <member name="T:Confluent.Kafka.WatermarkOffsets">
            <summary>
                Represents the low and high watermark offsets of
                a Kafka topic/partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.WatermarkOffsets.#ctor(Confluent.Kafka.Offset,Confluent.Kafka.Offset)">
            <summary>
                Initializes a new instance of the WatermarkOffsets class
                with the specified offsets.
            </summary>
            <param name="low">
                The offset of the earlist message in the topic/partition.
            </param>
            <param name="high">
                The offset of the last stored message in the topic/partition.
            </param>
        </member>
        <member name="P:Confluent.Kafka.WatermarkOffsets.Low">
            <summary>
                Gets the offset of the earlist message in the topic/partition.
            </summary>
        </member>
        <member name="P:Confluent.Kafka.WatermarkOffsets.High">
            <summary>
                Gets the offset of the last stored message in the topic/partition.
            </summary>
        </member>
        <member name="M:Confluent.Kafka.WatermarkOffsets.ToString">
            <summary>
                Returns a string representation of the WatermarkOffsets object.
            </summary>
            <returns>
                A string representation of the WatermarkOffsets object.
            </returns>
        </member>
    </members>
</doc>
